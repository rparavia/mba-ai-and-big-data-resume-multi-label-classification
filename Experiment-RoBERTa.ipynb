{"cells":[{"cell_type":"markdown","metadata":{"id":"kxYEAvdFjCSl"},"source":["# 1. Downloading the Resume Corpus"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6519,"status":"ok","timestamp":1661702855943,"user":{"displayName":"Rafael Paravia","userId":"14697750106415239588"},"user_tz":420},"id":"dUG1Q25SjRbY","outputId":"36e6dc44-bba7-4dde-fe07-7de10cb880f1"},"outputs":[{"output_type":"stream","name":"stdout","text":["fatal: destination path 'resume_corpus' already exists and is not an empty directory.\n","mv: cannot move 'resume_corpus' to 'resume_corpus_repo/resume_corpus': Directory not empty\n","mkdir: cannot create directory ‘corpus’: File exists\n"]}],"source":["!git clone https://github.com/florex/resume_corpus.git\n","!mv resume_corpus resume_corpus_repo\n","!mkdir corpus && unzip resume_corpus_repo/resumes_corpus.zip -d corpus\n","!pip install -q scikit-multilearn\n","!pip install -q transformers"]},{"cell_type":"markdown","source":["# 2. Importing libraries"],"metadata":{"id":"09u3eC_wGrdM"}},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","import numpy as np\n","import os\n","import pandas as pd\n","import random\n","import re\n","import torch\n","import transformers\n","\n","from datetime import datetime\n","from sklearn.metrics import hamming_loss, accuracy_score, classification_report, multilabel_confusion_matrix\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import MultiLabelBinarizer\n","from torch.optim.lr_scheduler import ExponentialLR\n","from torch.utils.data import Dataset, DataLoader"],"metadata":{"id":"kJqxe1njG3Ms","executionInfo":{"status":"ok","timestamp":1661702857187,"user_tz":420,"elapsed":1252,"user":{"displayName":"Rafael Paravia","userId":"14697750106415239588"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["# Set random seed - being able to reproduce the experiment\n","SEED = 1\n","\n","random.seed(SEED)\n","os.environ['PYTHONHASHSEED'] = str(SEED)\n","np.random.seed(SEED)\n","torch.manual_seed(SEED)\n","torch.cuda.manual_seed(SEED)\n","torch.backends.cudnn.deterministic = True"],"metadata":{"id":"IKLbJpxBG62v","executionInfo":{"status":"ok","timestamp":1661702857189,"user_tz":420,"elapsed":11,"user":{"displayName":"Rafael Paravia","userId":"14697750106415239588"}}},"execution_count":3,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"3gnkFpb4kRfP"},"source":["# 3. Reading the corpus"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"e2UTY9Nqkf_o","executionInfo":{"status":"ok","timestamp":1661702858479,"user_tz":420,"elapsed":1300,"user":{"displayName":"Rafael Paravia","userId":"14697750106415239588"}}},"outputs":[],"source":["resume_text, resume_labels = {}, {}\n","for filename in os.listdir('corpus'):\n","  index = int(filename.replace('.lab', '').replace('.txt', '')) - 1\n","  with open('corpus/' + filename, encoding='latin1') as f:\n","    if filename.endswith('txt'):\n","      resume_text[index] = f.read()\n","    elif filename.endswith('lab'):\n","      resume_labels[index] = f.read().splitlines()\n","\n","txt_series = pd.Series(resume_text, name='text')\n","lbl_series = pd.Series(resume_labels, name='labels')\n","df = pd.concat([txt_series, lbl_series], axis=1)"]},{"cell_type":"markdown","metadata":{"id":"wkKrS2M0LorI"},"source":["# 4. One-Hot Encoding"]},{"cell_type":"code","source":["mlb = MultiLabelBinarizer()\n","one_hot_encoding = pd.DataFrame(mlb.fit_transform(df['labels']), index=df.index, columns=mlb.classes_)\n","df = pd.concat([df.drop('labels', 1), one_hot_encoding], axis=1)\n","df['labels'] = df[df.columns[1:]].values.tolist()\n","df.head()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":567},"id":"AYgtvzP9pmyW","executionInfo":{"status":"ok","timestamp":1661702858480,"user_tz":420,"elapsed":19,"user":{"displayName":"Rafael Paravia","userId":"14697750106415239588"}},"outputId":"7b49466a-7113-44ef-8e99-c1654f78954b"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n","  This is separate from the ipykernel package so we can avoid doing imports until\n"]},{"output_type":"execute_result","data":{"text/plain":["                                                text  Database_Administrator  \\\n","0  Database Administrator <span class=\"hl\">Databa...                       1   \n","1  Database Administrator <span class=\"hl\">Databa...                       1   \n","2  Oracle Database Administrator Oracle <span cla...                       1   \n","3  Amazon Redshift Administrator and ETL Develope...                       1   \n","4  Scrum Master Scrum Master Scrum Master Richmon...                       1   \n","\n","   Front_End_Developer  Java_Developer  Network_Administrator  \\\n","0                    0               0                      0   \n","1                    0               0                      0   \n","2                    0               0                      0   \n","3                    0               0                      0   \n","4                    0               0                      0   \n","\n","   Project_manager  Python_Developer  Security_Analyst  Software_Developer  \\\n","0                0                 0                 0                   0   \n","1                0                 0                 0                   0   \n","2                0                 0                 0                   0   \n","3                0                 0                 0                   0   \n","4                0                 0                 0                   0   \n","\n","   Systems_Administrator  Web_Developer                          labels  \n","0                      0              0  [1, 0, 0, 0, 0, 0, 0, 0, 0, 0]  \n","1                      0              0  [1, 0, 0, 0, 0, 0, 0, 0, 0, 0]  \n","2                      0              0  [1, 0, 0, 0, 0, 0, 0, 0, 0, 0]  \n","3                      0              0  [1, 0, 0, 0, 0, 0, 0, 0, 0, 0]  \n","4                      0              0  [1, 0, 0, 0, 0, 0, 0, 0, 0, 0]  "],"text/html":["\n","  <div id=\"df-0aa3e2a3-4e64-4a9c-90bf-675b94f3f426\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>text</th>\n","      <th>Database_Administrator</th>\n","      <th>Front_End_Developer</th>\n","      <th>Java_Developer</th>\n","      <th>Network_Administrator</th>\n","      <th>Project_manager</th>\n","      <th>Python_Developer</th>\n","      <th>Security_Analyst</th>\n","      <th>Software_Developer</th>\n","      <th>Systems_Administrator</th>\n","      <th>Web_Developer</th>\n","      <th>labels</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Database Administrator &lt;span class=\"hl\"&gt;Databa...</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>[1, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Database Administrator &lt;span class=\"hl\"&gt;Databa...</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>[1, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Oracle Database Administrator Oracle &lt;span cla...</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>[1, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Amazon Redshift Administrator and ETL Develope...</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>[1, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Scrum Master Scrum Master Scrum Master Richmon...</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>[1, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0aa3e2a3-4e64-4a9c-90bf-675b94f3f426')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-0aa3e2a3-4e64-4a9c-90bf-675b94f3f426 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-0aa3e2a3-4e64-4a9c-90bf-675b94f3f426');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":5}]},{"cell_type":"markdown","source":["# 5. Sampling"],"metadata":{"id":"rgECCE88_HEH"}},{"cell_type":"code","source":["def check_dataframe():\n","  df_cp = df.drop(columns=['text', 'labels'])\n","  row_sum=df_cp.iloc[:,:].sum(axis=1)\n","\n","  print(\"Total number of articles = \", len(df_cp))\n","  print(\"Total number of articles without label = \", row_sum[row_sum==0].count())\n","  print(\"Total labels = \", row_sum.sum())\n","  print(\"\\nCount by label:\")\n","  print(df_cp.iloc[:,:].sum())\n","  print('-------------------------------------------')\n","\n","check_dataframe()\n","df = df.sample(n=20000, random_state=SEED)\n","check_dataframe()\n","\n","df = df[['text', 'labels']]\n","df.head()"],"metadata":{"id":"TNxX_kyapt1g","executionInfo":{"status":"ok","timestamp":1661702858483,"user_tz":420,"elapsed":19,"user":{"displayName":"Rafael Paravia","userId":"14697750106415239588"}},"colab":{"base_uri":"https://localhost:8080/","height":827},"outputId":"eb64e166-91b9-4edc-d25e-b8f58deb3b7f"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Total number of articles =  29783\n","Total number of articles without label =  748\n","Total labels =  52972\n","\n","Count by label:\n","Database_Administrator     3299\n","Front_End_Developer        3977\n","Java_Developer             3252\n","Network_Administrator      4460\n","Project_manager            4550\n","Python_Developer           2836\n","Security_Analyst           3022\n","Software_Developer        15013\n","Systems_Administrator      5969\n","Web_Developer              6594\n","dtype: int64\n","-------------------------------------------\n","Total number of articles =  20000\n","Total number of articles without label =  513\n","Total labels =  35675\n","\n","Count by label:\n","Database_Administrator     2191\n","Front_End_Developer        2691\n","Java_Developer             2224\n","Network_Administrator      2981\n","Project_manager            3035\n","Python_Developer           1922\n","Security_Analyst           2042\n","Software_Developer        10118\n","Systems_Administrator      4022\n","Web_Developer              4449\n","dtype: int64\n","-------------------------------------------\n"]},{"output_type":"execute_result","data":{"text/plain":["                                                    text  \\\n","17832  Data Mining Project Data Mining Project Comput...   \n","12361  Sr. Java/J2EE developer Sr. <span class=\"hl\">J...   \n","9759   Cyber Security Analyst Cyber <span class=\"hl\">...   \n","23312  Hadoop Developer Hadoop <span class=\"hl\">Devel...   \n","11431  Security Automation Analyst (ITS2) <span class...   \n","\n","                               labels  \n","17832  [0, 0, 0, 0, 0, 1, 0, 1, 0, 0]  \n","12361  [0, 0, 1, 0, 0, 0, 0, 1, 0, 1]  \n","9759   [0, 0, 0, 0, 0, 0, 1, 0, 0, 0]  \n","23312  [0, 0, 0, 0, 0, 0, 0, 1, 0, 0]  \n","11431  [0, 0, 0, 0, 0, 0, 1, 0, 0, 0]  "],"text/html":["\n","  <div id=\"df-ed0fd29d-2c5b-4798-b9ea-e6f01039aed5\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>text</th>\n","      <th>labels</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>17832</th>\n","      <td>Data Mining Project Data Mining Project Comput...</td>\n","      <td>[0, 0, 0, 0, 0, 1, 0, 1, 0, 0]</td>\n","    </tr>\n","    <tr>\n","      <th>12361</th>\n","      <td>Sr. Java/J2EE developer Sr. &lt;span class=\"hl\"&gt;J...</td>\n","      <td>[0, 0, 1, 0, 0, 0, 0, 1, 0, 1]</td>\n","    </tr>\n","    <tr>\n","      <th>9759</th>\n","      <td>Cyber Security Analyst Cyber &lt;span class=\"hl\"&gt;...</td>\n","      <td>[0, 0, 0, 0, 0, 0, 1, 0, 0, 0]</td>\n","    </tr>\n","    <tr>\n","      <th>23312</th>\n","      <td>Hadoop Developer Hadoop &lt;span class=\"hl\"&gt;Devel...</td>\n","      <td>[0, 0, 0, 0, 0, 0, 0, 1, 0, 0]</td>\n","    </tr>\n","    <tr>\n","      <th>11431</th>\n","      <td>Security Automation Analyst (ITS2) &lt;span class...</td>\n","      <td>[0, 0, 0, 0, 0, 0, 1, 0, 0, 0]</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ed0fd29d-2c5b-4798-b9ea-e6f01039aed5')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-ed0fd29d-2c5b-4798-b9ea-e6f01039aed5 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-ed0fd29d-2c5b-4798-b9ea-e6f01039aed5');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":6}]},{"cell_type":"markdown","metadata":{"id":"jGRaoVLm87ZZ"},"source":["# 6. Text Cleanup"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"clHEDLBo9Elv","executionInfo":{"status":"ok","timestamp":1661702865489,"user_tz":420,"elapsed":7020,"user":{"displayName":"Rafael Paravia","userId":"14697750106415239588"}},"colab":{"base_uri":"https://localhost:8080/","height":206},"outputId":"51bb9083-9bbb-4165-83b4-5a06580a8e1f"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                                    text  \\\n","17832  Data Mining Project Data Mining Project Comput...   \n","12361  Sr. Java/J2EE developer Sr. Java/J2EE develope...   \n","9759   Cyber Security Analyst Cyber Security Analyst ...   \n","23312  Hadoop Developer Hadoop Developer Hadoop Devel...   \n","11431  Security Automation Analyst (ITS2) Security Au...   \n","\n","                               labels  \n","17832  [0, 0, 0, 0, 0, 1, 0, 1, 0, 0]  \n","12361  [0, 0, 1, 0, 0, 0, 0, 1, 0, 1]  \n","9759   [0, 0, 0, 0, 0, 0, 1, 0, 0, 0]  \n","23312  [0, 0, 0, 0, 0, 0, 0, 1, 0, 0]  \n","11431  [0, 0, 0, 0, 0, 0, 1, 0, 0, 0]  "],"text/html":["\n","  <div id=\"df-6239a42d-95d6-4467-943b-a0e60df3ef7d\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>text</th>\n","      <th>labels</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>17832</th>\n","      <td>Data Mining Project Data Mining Project Comput...</td>\n","      <td>[0, 0, 0, 0, 0, 1, 0, 1, 0, 0]</td>\n","    </tr>\n","    <tr>\n","      <th>12361</th>\n","      <td>Sr. Java/J2EE developer Sr. Java/J2EE develope...</td>\n","      <td>[0, 0, 1, 0, 0, 0, 0, 1, 0, 1]</td>\n","    </tr>\n","    <tr>\n","      <th>9759</th>\n","      <td>Cyber Security Analyst Cyber Security Analyst ...</td>\n","      <td>[0, 0, 0, 0, 0, 0, 1, 0, 0, 0]</td>\n","    </tr>\n","    <tr>\n","      <th>23312</th>\n","      <td>Hadoop Developer Hadoop Developer Hadoop Devel...</td>\n","      <td>[0, 0, 0, 0, 0, 0, 0, 1, 0, 0]</td>\n","    </tr>\n","    <tr>\n","      <th>11431</th>\n","      <td>Security Automation Analyst (ITS2) Security Au...</td>\n","      <td>[0, 0, 0, 0, 0, 0, 1, 0, 0, 0]</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6239a42d-95d6-4467-943b-a0e60df3ef7d')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-6239a42d-95d6-4467-943b-a0e60df3ef7d button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-6239a42d-95d6-4467-943b-a0e60df3ef7d');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":7}],"source":["def remove_html_tags(text):\n","  return re.sub(\"<.*?>\", \"\", text)\n","\n","def remove_irrelevant_symbols(text):\n","    text = re.sub(\"[^a-zA-Z0-9\\.,;\\?!-/\\\\\\\\]\", \" \", text) \n","    return ' '.join(text.split())\n"," \n","df['text'] = df['text'].apply(remove_html_tags).apply(remove_irrelevant_symbols)\n","df.head()"]},{"cell_type":"markdown","source":["# 7. Definig Datasets and Configurations"],"metadata":{"id":"oTYDW6SWJ8gJ"}},{"cell_type":"code","execution_count":8,"metadata":{"id":"AAzSr3NrOGa1","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1661702874501,"user_tz":420,"elapsed":9024,"user":{"displayName":"Rafael Paravia","userId":"14697750106415239588"}},"outputId":"818eae31-06d5-43cc-fdfb-5dc7f183d498"},"outputs":[{"output_type":"stream","name":"stdout","text":["Using cuda device\n"]}],"source":["TOKENS_MAX_LEN = 500\n","TRAIN_BATCH_SIZE = 16\n","DEFAULT_BATCH_SIZE = 16\n","EPOCHS = 50\n","LEARNING_RATE = 0.0001\n","TOKENIZER = transformers.AutoTokenizer.from_pretrained('roberta-base')\n","DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","FINAL_MODEL_PATH = 'final_model.pth'\n","\n","print(f\"Using {DEVICE} device\")"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"CPHvfwpyu5AV","executionInfo":{"status":"ok","timestamp":1661702874502,"user_tz":420,"elapsed":19,"user":{"displayName":"Rafael Paravia","userId":"14697750106415239588"}}},"outputs":[],"source":["class ResumeDataset(Dataset):\n","    def _tokenize(text):\n","        return TOKENIZER.encode_plus(\n","            text,\n","            None,\n","            add_special_tokens=True,\n","            max_length=TOKENS_MAX_LEN,\n","            pad_to_max_length=True,\n","            return_token_type_ids=True,\n","            padding='max_length',\n","            truncation=True\n","        )\n","\n","    def __init__(self, dataframe):\n","        self.dataframe = dataframe\n","        self.tokens = [ResumeDataset._tokenize(txt) for txt in dataframe.text]\n","\n","    def __len__(self):\n","        return len(self.dataframe.text) # number of documents\n","\n","    def __getitem__(self, index):\n","        inputs = self.tokens[index]\n","        return {\n","            'ids': torch.tensor(inputs['input_ids'], dtype=torch.long),\n","            'mask': torch.tensor(inputs['attention_mask'], dtype=torch.long),\n","            'token_type_ids': torch.tensor(inputs[\"token_type_ids\"], dtype=torch.long),\n","            'targets': torch.tensor(self.dataframe.labels[index], dtype=torch.float)\n","        }"]},{"cell_type":"code","source":["train_dataset, test_dataset = train_test_split(df, test_size=0.2, random_state=SEED)\n","train_dataset, validation_dataset = train_test_split(train_dataset, test_size=0.25, random_state=SEED)\n","\n","training_set = ResumeDataset(train_dataset.reset_index(drop=True))\n","validation_set = ResumeDataset(validation_dataset.reset_index(drop=True))\n","testing_set = ResumeDataset(test_dataset.reset_index(drop=True))\n","\n","print(f'{len(training_set)} documents for training dataset')\n","print(f'{len(validation_set)} documents for validation dataset')\n","print(f'{len(testing_set)} documents for testing dataset')"],"metadata":{"id":"ZbfjxMTHWYtm","executionInfo":{"status":"ok","timestamp":1661702936498,"user_tz":420,"elapsed":62012,"user":{"displayName":"Rafael Paravia","userId":"14697750106415239588"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"e4ec5411-9c10-4488-e06d-a501290df568"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["12000 documents for training dataset\n","4000 documents for validation dataset\n","4000 documents for testing dataset\n"]}]},{"cell_type":"markdown","source":["# 8. Defining Loaders and Model"],"metadata":{"id":"CB5eg5IlOCW1"}},{"cell_type":"code","source":["def seed_worker(worker_id):\n","    np.random.seed(SEED)\n","    random.seed(SEED)\n","\n","g = torch.Generator()\n","g.manual_seed(SEED)\n","\n","training_loader = DataLoader(training_set, batch_size=TRAIN_BATCH_SIZE, shuffle=True, num_workers=0, worker_init_fn=seed_worker, generator=g)\n","validation_loader = DataLoader(validation_set, batch_size=DEFAULT_BATCH_SIZE, shuffle=True, num_workers=0, worker_init_fn=seed_worker, generator=g)\n","testing_loader = DataLoader(testing_set, batch_size=DEFAULT_BATCH_SIZE, shuffle=True, num_workers=0, worker_init_fn=seed_worker, generator=g)"],"metadata":{"id":"DzDRHBhyXeWs","executionInfo":{"status":"ok","timestamp":1661702936499,"user_tz":420,"elapsed":35,"user":{"displayName":"Rafael Paravia","userId":"14697750106415239588"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["class Model(torch.nn.Module):\n","    def __init__(self):\n","        super(Model, self).__init__()\n","        self.bert = transformers.AutoModel.from_pretrained('roberta-base', return_dict=False)\n","        self.dropout = torch.nn.Dropout(0.3)\n","        self.linear = torch.nn.Linear(768, 10)\n","    \n","    def forward(self, ids, mask, token_type_ids):\n","        _, bert_output = self.bert(ids, attention_mask = mask, token_type_ids = token_type_ids)\n","        droput_output = self.dropout(bert_output)\n","        return self.linear(droput_output)\n","\n","model = Model()\n","model.to(DEVICE)"],"metadata":{"id":"PuySzfU4avxV","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1661702941618,"user_tz":420,"elapsed":5150,"user":{"displayName":"Rafael Paravia","userId":"14697750106415239588"}},"outputId":"76750f01-f07f-4f8b-9f64-09ffc50e7f7a"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.decoder.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.weight', 'lm_head.dense.bias']\n","- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"execute_result","data":{"text/plain":["Model(\n","  (bert): RobertaModel(\n","    (embeddings): RobertaEmbeddings(\n","      (word_embeddings): Embedding(50265, 768, padding_idx=1)\n","      (position_embeddings): Embedding(514, 768, padding_idx=1)\n","      (token_type_embeddings): Embedding(1, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): RobertaEncoder(\n","      (layer): ModuleList(\n","        (0): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (1): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (2): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (3): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (4): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (5): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (6): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (7): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (8): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (9): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (10): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (11): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (pooler): RobertaPooler(\n","      (dense): Linear(in_features=768, out_features=768, bias=True)\n","      (activation): Tanh()\n","    )\n","  )\n","  (dropout): Dropout(p=0.3, inplace=False)\n","  (linear): Linear(in_features=768, out_features=10, bias=True)\n",")"]},"metadata":{},"execution_count":12}]},{"cell_type":"markdown","source":["# 9. Training the Model"],"metadata":{"id":"3uwMph0LObZ0"}},{"cell_type":"code","source":["optimizer = torch.optim.Adam(params=model.parameters(), lr=LEARNING_RATE)\n","lr_scheduler = ExponentialLR(optimizer, gamma=0.95)\n","total_training_steps = len(training_loader)\n","train_losses = []\n","\n","def loss_fn(outputs, targets):\n","    return torch.nn.BCEWithLogitsLoss()(outputs, targets)\n","\n","def train(epoch):\n","    model.train()\n","    total_loss, running_loss = 0.0, 0.0\n","    for step, data in enumerate(training_loader, 0):\n","        ids = data['ids'].to(DEVICE, dtype = torch.long)\n","        mask = data['mask'].to(DEVICE, dtype = torch.long)\n","        token_type_ids = data['token_type_ids'].to(DEVICE, dtype = torch.long)\n","        outputs = model(ids, mask, token_type_ids)\n","\n","        optimizer.zero_grad()\n","\n","        targets = data['targets'].to(DEVICE, dtype = torch.float)\n","        loss = loss_fn(outputs, targets)\n","\n","        loss_item = loss.item()        \n","        running_loss += loss_item\n","        total_loss += loss_item\n","\n","        if step % 50 == 49:\n","            print(f'[{datetime.now()}] Epoch: {epoch}, Step: {step+1}/{total_training_steps}, Avg. Running Loss: {running_loss / 50:.3f}')\n","            running_loss = 0.0\n","        \n","        loss.backward()\n","        optimizer.step()\n","    train_losses.append(total_loss / total_training_steps)"],"metadata":{"id":"jtzJBXLcZqmp","executionInfo":{"status":"ok","timestamp":1661702941620,"user_tz":420,"elapsed":11,"user":{"displayName":"Rafael Paravia","userId":"14697750106415239588"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["eval_accuracies = []\n","eval_hamming_losses = []\n","min_validation_loss = np.inf\n","\n","def evaluate(epoch):\n","    model.eval()\n","    targets=[]\n","    predictions=[]\n","    with torch.no_grad():\n","        for _, data in enumerate(validation_loader, 0):\n","            ids = data['ids'].to(DEVICE, dtype = torch.long)\n","            mask = data['mask'].to(DEVICE, dtype = torch.long)\n","            token_type_ids = data['token_type_ids'].to(DEVICE, dtype = torch.long)\n","            batch_targets = data['targets'].to(DEVICE, dtype = torch.float)\n","            batch_predictions = model(ids, mask, token_type_ids)\n","            targets.extend(batch_targets.cpu().detach().numpy().tolist())\n","            predictions.extend(torch.sigmoid(batch_predictions).cpu().detach().numpy().tolist())\n","    predictions = np.array(predictions) >= 0.5\n","    \n","    accuracy = accuracy_score(targets, predictions)\n","    eval_accuracies.append(accuracy)\n","    h_loss = hamming_loss(targets, predictions)\n","    eval_hamming_losses.append(h_loss)\n","\n","    print('----------------------------------------------------------------------')\n","    print(f'[{datetime.now()}] Epoch: {epoch}, Accuracy (Exact Match Ratio) Score={accuracy}')\n","    print(f'[{datetime.now()}] Epoch: {epoch}, Hamming Loss={h_loss}')\n","    print(f'[{datetime.now()}] Epoch: {epoch}, Classification Report:')\n","    print(classification_report(targets, predictions, digits=4, zero_division=0, target_names=mlb.classes_))\n","\n","    global min_validation_loss\n","    if min_validation_loss > h_loss:\n","        print(f'Validation Loss Decreased({min_validation_loss:.6f}--->{h_loss:.6f}) \\t Saving The Model')\n","        min_validation_loss = h_loss\n","        torch.save(model, FINAL_MODEL_PATH)\n","    print('----------------------------------------------------------------------')"],"metadata":{"id":"IGP95g6HO9c3","executionInfo":{"status":"ok","timestamp":1661702941620,"user_tz":420,"elapsed":10,"user":{"displayName":"Rafael Paravia","userId":"14697750106415239588"}}},"execution_count":14,"outputs":[]},{"cell_type":"code","source":["for epoch in range(EPOCHS):\n","    train(epoch)\n","    evaluate(epoch)\n","    lr_scheduler.step()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"U2E4lntcOsND","executionInfo":{"status":"ok","timestamp":1661770733560,"user_tz":420,"elapsed":67791949,"user":{"displayName":"Rafael Paravia","userId":"14697750106415239588"}},"outputId":"f245c9a3-7583-4384-9fc6-fe86a36aee87"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["[2022-08-28 16:10:11.030984] Epoch: 0, Step: 50/750, Avg. Running Loss: 0.382\n","[2022-08-28 16:11:25.817047] Epoch: 0, Step: 100/750, Avg. Running Loss: 0.287\n","[2022-08-28 16:12:43.461087] Epoch: 0, Step: 150/750, Avg. Running Loss: 0.243\n","[2022-08-28 16:14:03.460310] Epoch: 0, Step: 200/750, Avg. Running Loss: 0.207\n","[2022-08-28 16:15:23.463948] Epoch: 0, Step: 250/750, Avg. Running Loss: 0.194\n","[2022-08-28 16:16:43.849930] Epoch: 0, Step: 300/750, Avg. Running Loss: 0.194\n","[2022-08-28 16:18:04.395727] Epoch: 0, Step: 350/750, Avg. Running Loss: 0.192\n","[2022-08-28 16:19:24.678581] Epoch: 0, Step: 400/750, Avg. Running Loss: 0.218\n","[2022-08-28 16:20:44.910436] Epoch: 0, Step: 450/750, Avg. Running Loss: 0.239\n","[2022-08-28 16:22:05.325190] Epoch: 0, Step: 500/750, Avg. Running Loss: 0.179\n","[2022-08-28 16:23:25.838360] Epoch: 0, Step: 550/750, Avg. Running Loss: 0.159\n","[2022-08-28 16:24:46.470633] Epoch: 0, Step: 600/750, Avg. Running Loss: 0.157\n","[2022-08-28 16:26:06.896858] Epoch: 0, Step: 650/750, Avg. Running Loss: 0.150\n","[2022-08-28 16:27:27.457399] Epoch: 0, Step: 700/750, Avg. Running Loss: 0.144\n","[2022-08-28 16:28:47.928024] Epoch: 0, Step: 750/750, Avg. Running Loss: 0.145\n","----------------------------------------------------------------------\n","[2022-08-28 16:31:18.658658] Epoch: 0, Accuracy (Exact Match Ratio) Score=0.632\n","[2022-08-28 16:31:18.658720] Epoch: 0, Hamming Loss=0.047625\n","[2022-08-28 16:31:18.658754] Epoch: 0, Classification Report:\n","                        precision    recall  f1-score   support\n","\n","Database_Administrator     0.8662    0.8502    0.8581       434\n","   Front_End_Developer     0.9240    0.7703    0.8402       505\n","        Java_Developer     0.9556    0.7099    0.8146       455\n"," Network_Administrator     0.8272    0.7653    0.7951       588\n","       Project_manager     0.8846    0.8527    0.8683       611\n","      Python_Developer     0.8534    0.9126    0.8820       389\n","      Security_Analyst     0.8131    0.8741    0.8425       413\n","    Software_Developer     0.9809    0.9216    0.9503      2002\n"," Systems_Administrator     0.9075    0.7819    0.8400       816\n","         Web_Developer     0.7377    0.7621    0.7497       849\n","\n","             micro avg     0.8884    0.8352    0.8610      7062\n","             macro avg     0.8750    0.8201    0.8441      7062\n","          weighted avg     0.8925    0.8352    0.8611      7062\n","           samples avg     0.8948    0.8544    0.8542      7062\n","\n","Validation Loss Decreased(inf--->0.047625) \t Saving The Model\n","----------------------------------------------------------------------\n","[2022-08-28 16:32:39.113643] Epoch: 1, Step: 50/750, Avg. Running Loss: 0.135\n","[2022-08-28 16:33:59.601434] Epoch: 1, Step: 100/750, Avg. Running Loss: 0.130\n","[2022-08-28 16:35:20.057694] Epoch: 1, Step: 150/750, Avg. Running Loss: 0.145\n","[2022-08-28 16:36:40.345649] Epoch: 1, Step: 200/750, Avg. Running Loss: 0.134\n","[2022-08-28 16:38:00.946066] Epoch: 1, Step: 250/750, Avg. Running Loss: 0.131\n","[2022-08-28 16:39:21.658305] Epoch: 1, Step: 300/750, Avg. Running Loss: 0.135\n","[2022-08-28 16:40:41.929599] Epoch: 1, Step: 350/750, Avg. Running Loss: 0.142\n","[2022-08-28 16:42:02.370831] Epoch: 1, Step: 400/750, Avg. Running Loss: 0.134\n","[2022-08-28 16:43:22.674345] Epoch: 1, Step: 450/750, Avg. Running Loss: 0.133\n","[2022-08-28 16:44:42.952946] Epoch: 1, Step: 500/750, Avg. Running Loss: 0.130\n","[2022-08-28 16:46:03.215233] Epoch: 1, Step: 550/750, Avg. Running Loss: 0.142\n","[2022-08-28 16:47:23.735784] Epoch: 1, Step: 600/750, Avg. Running Loss: 0.136\n","[2022-08-28 16:48:43.929174] Epoch: 1, Step: 650/750, Avg. Running Loss: 0.124\n","[2022-08-28 16:50:04.187039] Epoch: 1, Step: 700/750, Avg. Running Loss: 0.115\n","[2022-08-28 16:51:24.455796] Epoch: 1, Step: 750/750, Avg. Running Loss: 0.130\n","----------------------------------------------------------------------\n","[2022-08-28 16:53:55.132831] Epoch: 1, Accuracy (Exact Match Ratio) Score=0.6795\n","[2022-08-28 16:53:55.132866] Epoch: 1, Hamming Loss=0.04045\n","[2022-08-28 16:53:55.132881] Epoch: 1, Classification Report:\n","                        precision    recall  f1-score   support\n","\n","Database_Administrator     0.9555    0.8410    0.8946       434\n","   Front_End_Developer     0.9429    0.8495    0.8937       505\n","        Java_Developer     0.9206    0.8154    0.8648       455\n"," Network_Administrator     0.8992    0.7432    0.8138       588\n","       Project_manager     0.8562    0.8674    0.8618       611\n","      Python_Developer     0.9073    0.9306    0.9188       389\n","      Security_Analyst     0.9463    0.7676    0.8476       413\n","    Software_Developer     0.9619    0.9585    0.9602      2002\n"," Systems_Administrator     0.8837    0.8100    0.8453       816\n","         Web_Developer     0.9088    0.6337    0.7467       849\n","\n","             micro avg     0.9244    0.8396    0.8799      7062\n","             macro avg     0.9182    0.8217    0.8647      7062\n","          weighted avg     0.9238    0.8396    0.8768      7062\n","           samples avg     0.9177    0.8586    0.8702      7062\n","\n","Validation Loss Decreased(0.047625--->0.040450) \t Saving The Model\n","----------------------------------------------------------------------\n","[2022-08-28 16:55:15.138771] Epoch: 2, Step: 50/750, Avg. Running Loss: 0.118\n","[2022-08-28 16:56:35.861096] Epoch: 2, Step: 100/750, Avg. Running Loss: 0.115\n","[2022-08-28 16:57:56.423565] Epoch: 2, Step: 150/750, Avg. Running Loss: 0.120\n","[2022-08-28 16:59:16.749570] Epoch: 2, Step: 200/750, Avg. Running Loss: 0.111\n","[2022-08-28 17:00:37.085578] Epoch: 2, Step: 250/750, Avg. Running Loss: 0.130\n","[2022-08-28 17:01:57.509070] Epoch: 2, Step: 300/750, Avg. Running Loss: 0.109\n","[2022-08-28 17:03:17.763824] Epoch: 2, Step: 350/750, Avg. Running Loss: 0.117\n","[2022-08-28 17:04:37.995252] Epoch: 2, Step: 400/750, Avg. Running Loss: 0.121\n","[2022-08-28 17:05:58.179875] Epoch: 2, Step: 450/750, Avg. Running Loss: 0.108\n","[2022-08-28 17:07:18.583581] Epoch: 2, Step: 500/750, Avg. Running Loss: 0.138\n","[2022-08-28 17:08:39.090070] Epoch: 2, Step: 550/750, Avg. Running Loss: 0.124\n","[2022-08-28 17:09:59.512101] Epoch: 2, Step: 600/750, Avg. Running Loss: 0.123\n","[2022-08-28 17:11:19.826597] Epoch: 2, Step: 650/750, Avg. Running Loss: 0.115\n","[2022-08-28 17:12:40.116319] Epoch: 2, Step: 700/750, Avg. Running Loss: 0.114\n","[2022-08-28 17:14:00.490898] Epoch: 2, Step: 750/750, Avg. Running Loss: 0.120\n","----------------------------------------------------------------------\n","[2022-08-28 17:16:30.950001] Epoch: 2, Accuracy (Exact Match Ratio) Score=0.67975\n","[2022-08-28 17:16:30.950044] Epoch: 2, Hamming Loss=0.041075\n","[2022-08-28 17:16:30.950066] Epoch: 2, Classification Report:\n","                        precision    recall  f1-score   support\n","\n","Database_Administrator     0.9122    0.8618    0.8863       434\n","   Front_End_Developer     0.8446    0.9149    0.8783       505\n","        Java_Developer     0.9875    0.6923    0.8140       455\n"," Network_Administrator     0.7587    0.8129    0.7849       588\n","       Project_manager     0.9197    0.8805    0.8997       611\n","      Python_Developer     0.9295    0.9152    0.9223       389\n","      Security_Analyst     0.9506    0.7458    0.8358       413\n","    Software_Developer     0.9789    0.9505    0.9645      2002\n"," Systems_Administrator     0.9370    0.7831    0.8531       816\n","         Web_Developer     0.8158    0.7562    0.7848       849\n","\n","             micro avg     0.9098    0.8517    0.8798      7062\n","             macro avg     0.9034    0.8313    0.8624      7062\n","          weighted avg     0.9135    0.8517    0.8790      7062\n","           samples avg     0.9030    0.8649    0.8657      7062\n","\n","----------------------------------------------------------------------\n","[2022-08-28 17:17:50.525230] Epoch: 3, Step: 50/750, Avg. Running Loss: 0.138\n","[2022-08-28 17:19:10.661369] Epoch: 3, Step: 100/750, Avg. Running Loss: 0.120\n","[2022-08-28 17:20:30.760621] Epoch: 3, Step: 150/750, Avg. Running Loss: 0.111\n","[2022-08-28 17:21:50.991332] Epoch: 3, Step: 200/750, Avg. Running Loss: 0.121\n","[2022-08-28 17:23:11.559313] Epoch: 3, Step: 250/750, Avg. Running Loss: 0.109\n","[2022-08-28 17:24:32.155992] Epoch: 3, Step: 300/750, Avg. Running Loss: 0.097\n","[2022-08-28 17:25:52.781764] Epoch: 3, Step: 350/750, Avg. Running Loss: 0.128\n","[2022-08-28 17:27:13.404931] Epoch: 3, Step: 400/750, Avg. Running Loss: 0.109\n","[2022-08-28 17:28:33.963345] Epoch: 3, Step: 450/750, Avg. Running Loss: 0.116\n","[2022-08-28 17:29:54.439133] Epoch: 3, Step: 500/750, Avg. Running Loss: 0.127\n","[2022-08-28 17:31:14.721746] Epoch: 3, Step: 550/750, Avg. Running Loss: 0.118\n","[2022-08-28 17:32:34.794212] Epoch: 3, Step: 600/750, Avg. Running Loss: 0.107\n","[2022-08-28 17:33:55.192293] Epoch: 3, Step: 650/750, Avg. Running Loss: 0.107\n","[2022-08-28 17:35:15.574556] Epoch: 3, Step: 700/750, Avg. Running Loss: 0.111\n","[2022-08-28 17:36:36.046725] Epoch: 3, Step: 750/750, Avg. Running Loss: 0.119\n","----------------------------------------------------------------------\n","[2022-08-28 17:39:07.070018] Epoch: 3, Accuracy (Exact Match Ratio) Score=0.71525\n","[2022-08-28 17:39:07.070063] Epoch: 3, Hamming Loss=0.0361\n","[2022-08-28 17:39:07.070084] Epoch: 3, Classification Report:\n","                        precision    recall  f1-score   support\n","\n","Database_Administrator     0.9786    0.8410    0.9046       434\n","   Front_End_Developer     0.9240    0.8911    0.9073       505\n","        Java_Developer     0.9839    0.6725    0.7990       455\n"," Network_Administrator     0.9228    0.7721    0.8407       588\n","       Project_manager     0.9746    0.8167    0.8887       611\n","      Python_Developer     0.9211    0.9306    0.9258       389\n","      Security_Analyst     0.9324    0.8354    0.8812       413\n","    Software_Developer     0.9778    0.9471    0.9622      2002\n"," Systems_Administrator     0.9107    0.8248    0.8656       816\n","         Web_Developer     0.8892    0.7185    0.7948       849\n","\n","             micro avg     0.9457    0.8440    0.8919      7062\n","             macro avg     0.9415    0.8250    0.8770      7062\n","          weighted avg     0.9454    0.8440    0.8897      7062\n","           samples avg     0.9200    0.8572    0.8722      7062\n","\n","Validation Loss Decreased(0.040450--->0.036100) \t Saving The Model\n","----------------------------------------------------------------------\n","[2022-08-28 17:40:27.673238] Epoch: 4, Step: 50/750, Avg. Running Loss: 0.096\n","[2022-08-28 17:41:48.117772] Epoch: 4, Step: 100/750, Avg. Running Loss: 0.097\n","[2022-08-28 17:43:08.361771] Epoch: 4, Step: 150/750, Avg. Running Loss: 0.102\n","[2022-08-28 17:44:28.790995] Epoch: 4, Step: 200/750, Avg. Running Loss: 0.101\n","[2022-08-28 17:45:49.449614] Epoch: 4, Step: 250/750, Avg. Running Loss: 0.106\n","[2022-08-28 17:47:09.599539] Epoch: 4, Step: 300/750, Avg. Running Loss: 0.102\n","[2022-08-28 17:48:30.158665] Epoch: 4, Step: 350/750, Avg. Running Loss: 0.099\n","[2022-08-28 17:49:50.720578] Epoch: 4, Step: 400/750, Avg. Running Loss: 0.094\n","[2022-08-28 17:51:11.279741] Epoch: 4, Step: 450/750, Avg. Running Loss: 0.100\n","[2022-08-28 17:52:31.608456] Epoch: 4, Step: 500/750, Avg. Running Loss: 0.112\n","[2022-08-28 17:53:52.069328] Epoch: 4, Step: 550/750, Avg. Running Loss: 0.103\n","[2022-08-28 17:55:12.768731] Epoch: 4, Step: 600/750, Avg. Running Loss: 0.108\n","[2022-08-28 17:56:33.421347] Epoch: 4, Step: 650/750, Avg. Running Loss: 0.108\n","[2022-08-28 17:57:53.654239] Epoch: 4, Step: 700/750, Avg. Running Loss: 0.102\n","[2022-08-28 17:59:14.096968] Epoch: 4, Step: 750/750, Avg. Running Loss: 0.099\n","----------------------------------------------------------------------\n","[2022-08-28 18:01:45.064673] Epoch: 4, Accuracy (Exact Match Ratio) Score=0.69975\n","[2022-08-28 18:01:45.064728] Epoch: 4, Hamming Loss=0.03765\n","[2022-08-28 18:01:45.064761] Epoch: 4, Classification Report:\n","                        precision    recall  f1-score   support\n","\n","Database_Administrator     0.9296    0.8825    0.9054       434\n","   Front_End_Developer     0.9119    0.8812    0.8963       505\n","        Java_Developer     0.8614    0.8330    0.8469       455\n"," Network_Administrator     0.8900    0.7840    0.8336       588\n","       Project_manager     0.9168    0.8838    0.9000       611\n","      Python_Developer     0.9666    0.8920    0.9278       389\n","      Security_Analyst     0.9066    0.8692    0.8875       413\n","    Software_Developer     0.9735    0.9535    0.9634      2002\n"," Systems_Administrator     0.8866    0.8333    0.8591       816\n","         Web_Developer     0.7603    0.8257    0.7916       849\n","\n","             micro avg     0.9054    0.8785    0.8918      7062\n","             macro avg     0.9003    0.8638    0.8812      7062\n","          weighted avg     0.9073    0.8785    0.8922      7062\n","           samples avg     0.9046    0.8848    0.8786      7062\n","\n","----------------------------------------------------------------------\n","[2022-08-28 18:03:04.828461] Epoch: 5, Step: 50/750, Avg. Running Loss: 0.100\n","[2022-08-28 18:04:25.091089] Epoch: 5, Step: 100/750, Avg. Running Loss: 0.079\n","[2022-08-28 18:05:45.469917] Epoch: 5, Step: 150/750, Avg. Running Loss: 0.088\n","[2022-08-28 18:07:06.150936] Epoch: 5, Step: 200/750, Avg. Running Loss: 0.101\n","[2022-08-28 18:08:26.282298] Epoch: 5, Step: 250/750, Avg. Running Loss: 0.106\n","[2022-08-28 18:09:46.476542] Epoch: 5, Step: 300/750, Avg. Running Loss: 0.096\n","[2022-08-28 18:11:06.868027] Epoch: 5, Step: 350/750, Avg. Running Loss: 0.078\n","[2022-08-28 18:12:27.322725] Epoch: 5, Step: 400/750, Avg. Running Loss: 0.099\n","[2022-08-28 18:13:47.385373] Epoch: 5, Step: 450/750, Avg. Running Loss: 0.090\n","[2022-08-28 18:15:07.432029] Epoch: 5, Step: 500/750, Avg. Running Loss: 0.093\n","[2022-08-28 18:16:27.890105] Epoch: 5, Step: 550/750, Avg. Running Loss: 0.093\n","[2022-08-28 18:17:48.381127] Epoch: 5, Step: 600/750, Avg. Running Loss: 0.100\n","[2022-08-28 18:19:08.551867] Epoch: 5, Step: 650/750, Avg. Running Loss: 0.111\n","[2022-08-28 18:20:29.263949] Epoch: 5, Step: 700/750, Avg. Running Loss: 0.104\n","[2022-08-28 18:21:49.760114] Epoch: 5, Step: 750/750, Avg. Running Loss: 0.099\n","----------------------------------------------------------------------\n","[2022-08-28 18:24:20.535091] Epoch: 5, Accuracy (Exact Match Ratio) Score=0.717\n","[2022-08-28 18:24:20.535134] Epoch: 5, Hamming Loss=0.036175\n","[2022-08-28 18:24:20.535156] Epoch: 5, Classification Report:\n","                        precision    recall  f1-score   support\n","\n","Database_Administrator     0.9145    0.8871    0.9006       434\n","   Front_End_Developer     0.9615    0.8416    0.8976       505\n","        Java_Developer     0.9469    0.7846    0.8582       455\n"," Network_Administrator     0.9253    0.7789    0.8458       588\n","       Project_manager     0.9343    0.8609    0.8961       611\n","      Python_Developer     0.8993    0.9409    0.9196       389\n","      Security_Analyst     0.8856    0.8620    0.8736       413\n","    Software_Developer     0.9723    0.9481    0.9600      2002\n"," Systems_Administrator     0.8909    0.8407    0.8651       816\n","         Web_Developer     0.9316    0.6737    0.7820       849\n","\n","             micro avg     0.9357    0.8537    0.8929      7062\n","             macro avg     0.9262    0.8418    0.8798      7062\n","          weighted avg     0.9358    0.8537    0.8906      7062\n","           samples avg     0.9222    0.8701    0.8802      7062\n","\n","----------------------------------------------------------------------\n","[2022-08-28 18:25:40.337588] Epoch: 6, Step: 50/750, Avg. Running Loss: 0.080\n","[2022-08-28 18:27:00.550287] Epoch: 6, Step: 100/750, Avg. Running Loss: 0.085\n","[2022-08-28 18:28:21.088753] Epoch: 6, Step: 150/750, Avg. Running Loss: 0.093\n","[2022-08-28 18:29:41.603281] Epoch: 6, Step: 200/750, Avg. Running Loss: 0.083\n","[2022-08-28 18:31:02.146604] Epoch: 6, Step: 250/750, Avg. Running Loss: 0.084\n","[2022-08-28 18:32:22.592709] Epoch: 6, Step: 300/750, Avg. Running Loss: 0.101\n","[2022-08-28 18:33:43.245292] Epoch: 6, Step: 350/750, Avg. Running Loss: 0.083\n","[2022-08-28 18:35:03.844480] Epoch: 6, Step: 400/750, Avg. Running Loss: 0.092\n","[2022-08-28 18:36:24.300944] Epoch: 6, Step: 450/750, Avg. Running Loss: 0.083\n","[2022-08-28 18:37:44.960117] Epoch: 6, Step: 500/750, Avg. Running Loss: 0.089\n","[2022-08-28 18:39:05.181344] Epoch: 6, Step: 550/750, Avg. Running Loss: 0.085\n","[2022-08-28 18:40:25.551022] Epoch: 6, Step: 600/750, Avg. Running Loss: 0.090\n","[2022-08-28 18:41:46.266553] Epoch: 6, Step: 650/750, Avg. Running Loss: 0.086\n","[2022-08-28 18:43:06.680452] Epoch: 6, Step: 700/750, Avg. Running Loss: 0.081\n","[2022-08-28 18:44:26.922469] Epoch: 6, Step: 750/750, Avg. Running Loss: 0.092\n","----------------------------------------------------------------------\n","[2022-08-28 18:46:58.137769] Epoch: 6, Accuracy (Exact Match Ratio) Score=0.7\n","[2022-08-28 18:46:58.137845] Epoch: 6, Hamming Loss=0.038175\n","[2022-08-28 18:46:58.138629] Epoch: 6, Classification Report:\n","                        precision    recall  f1-score   support\n","\n","Database_Administrator     0.9356    0.8710    0.9021       434\n","   Front_End_Developer     0.9653    0.8257    0.8901       505\n","        Java_Developer     0.9428    0.7604    0.8418       455\n"," Network_Administrator     0.8244    0.8146    0.8195       588\n","       Project_manager     0.8934    0.8920    0.8927       611\n","      Python_Developer     0.9748    0.8946    0.9330       389\n","      Security_Analyst     0.8618    0.9056    0.8831       413\n","    Software_Developer     0.9798    0.9441    0.9616      2002\n"," Systems_Administrator     0.8954    0.8395    0.8665       816\n","         Web_Developer     0.7669    0.8292    0.7968       849\n","\n","             micro avg     0.9072    0.8731    0.8898      7062\n","             macro avg     0.9040    0.8577    0.8787      7062\n","          weighted avg     0.9107    0.8731    0.8904      7062\n","           samples avg     0.9041    0.8821    0.8761      7062\n","\n","----------------------------------------------------------------------\n","[2022-08-28 18:48:17.784678] Epoch: 7, Step: 50/750, Avg. Running Loss: 0.081\n","[2022-08-28 18:49:38.319348] Epoch: 7, Step: 100/750, Avg. Running Loss: 0.089\n","[2022-08-28 18:50:58.949861] Epoch: 7, Step: 150/750, Avg. Running Loss: 0.083\n","[2022-08-28 18:52:19.618524] Epoch: 7, Step: 200/750, Avg. Running Loss: 0.074\n","[2022-08-28 18:53:40.134938] Epoch: 7, Step: 250/750, Avg. Running Loss: 0.084\n","[2022-08-28 18:55:00.551101] Epoch: 7, Step: 300/750, Avg. Running Loss: 0.089\n","[2022-08-28 18:56:21.097617] Epoch: 7, Step: 350/750, Avg. Running Loss: 0.076\n","[2022-08-28 18:57:41.295054] Epoch: 7, Step: 400/750, Avg. Running Loss: 0.088\n","[2022-08-28 18:59:01.619578] Epoch: 7, Step: 450/750, Avg. Running Loss: 0.077\n","[2022-08-28 19:00:22.285847] Epoch: 7, Step: 500/750, Avg. Running Loss: 0.082\n","[2022-08-28 19:01:42.911982] Epoch: 7, Step: 550/750, Avg. Running Loss: 0.074\n","[2022-08-28 19:03:03.104061] Epoch: 7, Step: 600/750, Avg. Running Loss: 0.072\n","[2022-08-28 19:04:23.753898] Epoch: 7, Step: 650/750, Avg. Running Loss: 0.089\n","[2022-08-28 19:05:44.302310] Epoch: 7, Step: 700/750, Avg. Running Loss: 0.096\n","[2022-08-28 19:07:04.839994] Epoch: 7, Step: 750/750, Avg. Running Loss: 0.078\n","----------------------------------------------------------------------\n","[2022-08-28 19:09:36.184941] Epoch: 7, Accuracy (Exact Match Ratio) Score=0.7105\n","[2022-08-28 19:09:36.184982] Epoch: 7, Hamming Loss=0.03695\n","[2022-08-28 19:09:36.184996] Epoch: 7, Classification Report:\n","                        precision    recall  f1-score   support\n","\n","Database_Administrator     0.9113    0.8756    0.8931       434\n","   Front_End_Developer     0.9006    0.8970    0.8988       505\n","        Java_Developer     0.9035    0.8440    0.8727       455\n"," Network_Administrator     0.7964    0.8316    0.8136       588\n","       Project_manager     0.8610    0.8920    0.8762       611\n","      Python_Developer     0.9492    0.9126    0.9305       389\n","      Security_Analyst     0.9209    0.8741    0.8969       413\n","    Software_Developer     0.9744    0.9491    0.9615      2002\n"," Systems_Administrator     0.9179    0.8223    0.8675       816\n","         Web_Developer     0.8364    0.8009    0.8183       849\n","\n","             micro avg     0.9075    0.8805    0.8938      7062\n","             macro avg     0.8972    0.8699    0.8829      7062\n","          weighted avg     0.9084    0.8805    0.8938      7062\n","           samples avg     0.9055    0.8866    0.8802      7062\n","\n","----------------------------------------------------------------------\n","[2022-08-28 19:10:55.799188] Epoch: 8, Step: 50/750, Avg. Running Loss: 0.076\n","[2022-08-28 19:12:16.155661] Epoch: 8, Step: 100/750, Avg. Running Loss: 0.067\n","[2022-08-28 19:13:36.663752] Epoch: 8, Step: 150/750, Avg. Running Loss: 0.075\n","[2022-08-28 19:14:57.163803] Epoch: 8, Step: 200/750, Avg. Running Loss: 0.078\n","[2022-08-28 19:16:17.539356] Epoch: 8, Step: 250/750, Avg. Running Loss: 0.067\n","[2022-08-28 19:17:38.135062] Epoch: 8, Step: 300/750, Avg. Running Loss: 0.077\n","[2022-08-28 19:18:58.322963] Epoch: 8, Step: 350/750, Avg. Running Loss: 0.064\n","[2022-08-28 19:20:18.597717] Epoch: 8, Step: 400/750, Avg. Running Loss: 0.071\n","[2022-08-28 19:21:39.240645] Epoch: 8, Step: 450/750, Avg. Running Loss: 0.070\n","[2022-08-28 19:22:59.896282] Epoch: 8, Step: 500/750, Avg. Running Loss: 0.076\n","[2022-08-28 19:24:20.418983] Epoch: 8, Step: 550/750, Avg. Running Loss: 0.082\n","[2022-08-28 19:25:40.947671] Epoch: 8, Step: 600/750, Avg. Running Loss: 0.071\n","[2022-08-28 19:27:01.237992] Epoch: 8, Step: 650/750, Avg. Running Loss: 0.076\n","[2022-08-28 19:28:21.781489] Epoch: 8, Step: 700/750, Avg. Running Loss: 0.073\n","[2022-08-28 19:29:42.030200] Epoch: 8, Step: 750/750, Avg. Running Loss: 0.070\n","----------------------------------------------------------------------\n","[2022-08-28 19:32:12.842976] Epoch: 8, Accuracy (Exact Match Ratio) Score=0.7275\n","[2022-08-28 19:32:12.843020] Epoch: 8, Hamming Loss=0.0347\n","[2022-08-28 19:32:12.843041] Epoch: 8, Classification Report:\n","                        precision    recall  f1-score   support\n","\n","Database_Administrator     0.9716    0.8687    0.9173       434\n","   Front_End_Developer     0.9155    0.9010    0.9082       505\n","        Java_Developer     0.9195    0.8286    0.8717       455\n"," Network_Administrator     0.8635    0.7959    0.8283       588\n","       Project_manager     0.9233    0.8871    0.9048       611\n","      Python_Developer     0.9547    0.9203    0.9372       389\n","      Security_Analyst     0.8726    0.8789    0.8758       413\n","    Software_Developer     0.9819    0.9466    0.9639      2002\n"," Systems_Administrator     0.9262    0.8150    0.8670       816\n","         Web_Developer     0.8528    0.7644    0.8062       849\n","\n","             micro avg     0.9283    0.8707    0.8986      7062\n","             macro avg     0.9182    0.8606    0.8880      7062\n","          weighted avg     0.9277    0.8707    0.8979      7062\n","           samples avg     0.9136    0.8792    0.8813      7062\n","\n","Validation Loss Decreased(0.036100--->0.034700) \t Saving The Model\n","----------------------------------------------------------------------\n","[2022-08-28 19:33:33.414313] Epoch: 9, Step: 50/750, Avg. Running Loss: 0.059\n","[2022-08-28 19:34:53.957050] Epoch: 9, Step: 100/750, Avg. Running Loss: 0.068\n","[2022-08-28 19:36:14.208631] Epoch: 9, Step: 150/750, Avg. Running Loss: 0.062\n","[2022-08-28 19:37:34.431568] Epoch: 9, Step: 200/750, Avg. Running Loss: 0.062\n","[2022-08-28 19:38:55.268205] Epoch: 9, Step: 250/750, Avg. Running Loss: 0.062\n","[2022-08-28 19:40:15.774139] Epoch: 9, Step: 300/750, Avg. Running Loss: 0.068\n","[2022-08-28 19:41:35.981946] Epoch: 9, Step: 350/750, Avg. Running Loss: 0.073\n","[2022-08-28 19:42:56.638400] Epoch: 9, Step: 400/750, Avg. Running Loss: 0.073\n","[2022-08-28 19:44:17.261642] Epoch: 9, Step: 450/750, Avg. Running Loss: 0.057\n","[2022-08-28 19:45:37.457169] Epoch: 9, Step: 500/750, Avg. Running Loss: 0.065\n","[2022-08-28 19:46:57.704734] Epoch: 9, Step: 550/750, Avg. Running Loss: 0.075\n","[2022-08-28 19:48:18.332731] Epoch: 9, Step: 600/750, Avg. Running Loss: 0.064\n","[2022-08-28 19:49:38.987199] Epoch: 9, Step: 650/750, Avg. Running Loss: 0.059\n","[2022-08-28 19:50:59.749183] Epoch: 9, Step: 700/750, Avg. Running Loss: 0.059\n","[2022-08-28 19:52:20.184955] Epoch: 9, Step: 750/750, Avg. Running Loss: 0.066\n","----------------------------------------------------------------------\n","[2022-08-28 19:54:50.394773] Epoch: 9, Accuracy (Exact Match Ratio) Score=0.72975\n","[2022-08-28 19:54:50.394816] Epoch: 9, Hamming Loss=0.034625\n","[2022-08-28 19:54:50.394839] Epoch: 9, Classification Report:\n","                        precision    recall  f1-score   support\n","\n","Database_Administrator     0.9114    0.9009    0.9061       434\n","   Front_End_Developer     0.9143    0.8871    0.9005       505\n","        Java_Developer     0.9584    0.7604    0.8480       455\n"," Network_Administrator     0.8287    0.8061    0.8172       588\n","       Project_manager     0.9065    0.8887    0.8975       611\n","      Python_Developer     0.9702    0.9203    0.9446       389\n","      Security_Analyst     0.8941    0.8789    0.8864       413\n","    Software_Developer     0.9844    0.9486    0.9662      2002\n"," Systems_Administrator     0.9286    0.8284    0.8756       816\n","         Web_Developer     0.8832    0.7656    0.8202       849\n","\n","             micro avg     0.9288    0.8706    0.8988      7062\n","             macro avg     0.9180    0.8585    0.8862      7062\n","          weighted avg     0.9289    0.8706    0.8980      7062\n","           samples avg     0.9145    0.8799    0.8823      7062\n","\n","Validation Loss Decreased(0.034700--->0.034625) \t Saving The Model\n","----------------------------------------------------------------------\n","[2022-08-28 19:56:11.152035] Epoch: 10, Step: 50/750, Avg. Running Loss: 0.047\n","[2022-08-28 19:57:31.725738] Epoch: 10, Step: 100/750, Avg. Running Loss: 0.061\n","[2022-08-28 19:58:52.021961] Epoch: 10, Step: 150/750, Avg. Running Loss: 0.059\n","[2022-08-28 20:00:12.616987] Epoch: 10, Step: 200/750, Avg. Running Loss: 0.057\n","[2022-08-28 20:01:33.279145] Epoch: 10, Step: 250/750, Avg. Running Loss: 0.066\n","[2022-08-28 20:02:53.828247] Epoch: 10, Step: 300/750, Avg. Running Loss: 0.067\n","[2022-08-28 20:04:14.446459] Epoch: 10, Step: 350/750, Avg. Running Loss: 0.060\n","[2022-08-28 20:05:35.114775] Epoch: 10, Step: 400/750, Avg. Running Loss: 0.057\n","[2022-08-28 20:06:55.474034] Epoch: 10, Step: 450/750, Avg. Running Loss: 0.056\n","[2022-08-28 20:08:15.829763] Epoch: 10, Step: 500/750, Avg. Running Loss: 0.058\n","[2022-08-28 20:09:36.516063] Epoch: 10, Step: 550/750, Avg. Running Loss: 0.060\n","[2022-08-28 20:10:56.764351] Epoch: 10, Step: 600/750, Avg. Running Loss: 0.056\n","[2022-08-28 20:12:17.110983] Epoch: 10, Step: 650/750, Avg. Running Loss: 0.062\n","[2022-08-28 20:13:37.752635] Epoch: 10, Step: 700/750, Avg. Running Loss: 0.062\n","[2022-08-28 20:14:58.101684] Epoch: 10, Step: 750/750, Avg. Running Loss: 0.061\n","----------------------------------------------------------------------\n","[2022-08-28 20:17:28.877635] Epoch: 10, Accuracy (Exact Match Ratio) Score=0.7215\n","[2022-08-28 20:17:28.877681] Epoch: 10, Hamming Loss=0.035475\n","[2022-08-28 20:17:28.877703] Epoch: 10, Classification Report:\n","                        precision    recall  f1-score   support\n","\n","Database_Administrator     0.9457    0.8825    0.9130       434\n","   Front_End_Developer     0.9272    0.8832    0.9047       505\n","        Java_Developer     0.9248    0.8110    0.8642       455\n"," Network_Administrator     0.8043    0.8248    0.8144       588\n","       Project_manager     0.9271    0.8740    0.8997       611\n","      Python_Developer     0.8976    0.9460    0.9212       389\n","      Security_Analyst     0.9390    0.8571    0.8962       413\n","    Software_Developer     0.9696    0.9550    0.9623      2002\n"," Systems_Administrator     0.9114    0.8321    0.8700       816\n","         Web_Developer     0.8380    0.8045    0.8209       849\n","\n","             micro avg     0.9160    0.8798    0.8975      7062\n","             macro avg     0.9085    0.8670    0.8866      7062\n","          weighted avg     0.9165    0.8798    0.8973      7062\n","           samples avg     0.9089    0.8855    0.8817      7062\n","\n","----------------------------------------------------------------------\n","[2022-08-28 20:18:48.571717] Epoch: 11, Step: 50/750, Avg. Running Loss: 0.054\n","[2022-08-28 20:20:08.986390] Epoch: 11, Step: 100/750, Avg. Running Loss: 0.053\n","[2022-08-28 20:21:29.525954] Epoch: 11, Step: 150/750, Avg. Running Loss: 0.057\n","[2022-08-28 20:22:50.269784] Epoch: 11, Step: 200/750, Avg. Running Loss: 0.048\n","[2022-08-28 20:24:10.914646] Epoch: 11, Step: 250/750, Avg. Running Loss: 0.053\n","[2022-08-28 20:25:31.446716] Epoch: 11, Step: 300/750, Avg. Running Loss: 0.054\n","[2022-08-28 20:26:52.039328] Epoch: 11, Step: 350/750, Avg. Running Loss: 0.055\n","[2022-08-28 20:28:12.700561] Epoch: 11, Step: 400/750, Avg. Running Loss: 0.056\n","[2022-08-28 20:29:33.340308] Epoch: 11, Step: 450/750, Avg. Running Loss: 0.051\n","[2022-08-28 20:30:53.599619] Epoch: 11, Step: 500/750, Avg. Running Loss: 0.056\n","[2022-08-28 20:32:13.823108] Epoch: 11, Step: 550/750, Avg. Running Loss: 0.058\n","[2022-08-28 20:33:34.505310] Epoch: 11, Step: 600/750, Avg. Running Loss: 0.061\n","[2022-08-28 20:34:55.079244] Epoch: 11, Step: 650/750, Avg. Running Loss: 0.049\n","[2022-08-28 20:36:15.509556] Epoch: 11, Step: 700/750, Avg. Running Loss: 0.053\n","[2022-08-28 20:37:36.119404] Epoch: 11, Step: 750/750, Avg. Running Loss: 0.053\n","----------------------------------------------------------------------\n","[2022-08-28 20:40:07.009894] Epoch: 11, Accuracy (Exact Match Ratio) Score=0.70375\n","[2022-08-28 20:40:07.009948] Epoch: 11, Hamming Loss=0.0386\n","[2022-08-28 20:40:07.009964] Epoch: 11, Classification Report:\n","                        precision    recall  f1-score   support\n","\n","Database_Administrator     0.9183    0.8802    0.8988       434\n","   Front_End_Developer     0.8490    0.9129    0.8798       505\n","        Java_Developer     0.8692    0.8615    0.8653       455\n"," Network_Administrator     0.8743    0.8044    0.8379       588\n","       Project_manager     0.9259    0.8592    0.8913       611\n","      Python_Developer     0.9242    0.9409    0.9325       389\n","      Security_Analyst     0.8374    0.9104    0.8724       413\n","    Software_Developer     0.9544    0.9610    0.9577      2002\n"," Systems_Administrator     0.8895    0.8578    0.8734       816\n","         Web_Developer     0.7569    0.8433    0.7978       849\n","\n","             micro avg     0.8879    0.8942    0.8911      7062\n","             macro avg     0.8799    0.8832    0.8807      7062\n","          weighted avg     0.8903    0.8942    0.8915      7062\n","           samples avg     0.8958    0.8963    0.8800      7062\n","\n","----------------------------------------------------------------------\n","[2022-08-28 20:41:26.679751] Epoch: 12, Step: 50/750, Avg. Running Loss: 0.049\n","[2022-08-28 20:42:46.908807] Epoch: 12, Step: 100/750, Avg. Running Loss: 0.052\n","[2022-08-28 20:44:07.304372] Epoch: 12, Step: 150/750, Avg. Running Loss: 0.047\n","[2022-08-28 20:45:28.013776] Epoch: 12, Step: 200/750, Avg. Running Loss: 0.054\n","[2022-08-28 20:46:48.507244] Epoch: 12, Step: 250/750, Avg. Running Loss: 0.047\n","[2022-08-28 20:48:09.194033] Epoch: 12, Step: 300/750, Avg. Running Loss: 0.047\n","[2022-08-28 20:49:29.638447] Epoch: 12, Step: 350/750, Avg. Running Loss: 0.037\n","[2022-08-28 20:50:49.849204] Epoch: 12, Step: 400/750, Avg. Running Loss: 0.051\n","[2022-08-28 20:52:10.297042] Epoch: 12, Step: 450/750, Avg. Running Loss: 0.053\n","[2022-08-28 20:53:31.005442] Epoch: 12, Step: 500/750, Avg. Running Loss: 0.052\n","[2022-08-28 20:54:51.280612] Epoch: 12, Step: 550/750, Avg. Running Loss: 0.053\n","[2022-08-28 20:56:12.046533] Epoch: 12, Step: 600/750, Avg. Running Loss: 0.048\n","[2022-08-28 20:57:32.837829] Epoch: 12, Step: 650/750, Avg. Running Loss: 0.046\n","[2022-08-28 20:58:53.301808] Epoch: 12, Step: 700/750, Avg. Running Loss: 0.051\n","[2022-08-28 21:00:13.781769] Epoch: 12, Step: 750/750, Avg. Running Loss: 0.051\n","----------------------------------------------------------------------\n","[2022-08-28 21:02:44.244816] Epoch: 12, Accuracy (Exact Match Ratio) Score=0.71925\n","[2022-08-28 21:02:44.244867] Epoch: 12, Hamming Loss=0.036875\n","[2022-08-28 21:02:44.244899] Epoch: 12, Classification Report:\n","                        precision    recall  f1-score   support\n","\n","Database_Administrator     0.8952    0.9055    0.9003       434\n","   Front_End_Developer     0.9124    0.8871    0.8996       505\n","        Java_Developer     0.9254    0.7912    0.8531       455\n"," Network_Administrator     0.8176    0.8231    0.8203       588\n","       Project_manager     0.9366    0.8707    0.9025       611\n","      Python_Developer     0.9332    0.9332    0.9332       389\n","      Security_Analyst     0.8651    0.9007    0.8826       413\n","    Software_Developer     0.9637    0.9555    0.9596      2002\n"," Systems_Administrator     0.8686    0.8591    0.8638       816\n","         Web_Developer     0.7998    0.8563    0.8271       849\n","\n","             micro avg     0.8991    0.8911    0.8951      7062\n","             macro avg     0.8918    0.8783    0.8842      7062\n","          weighted avg     0.9007    0.8911    0.8953      7062\n","           samples avg     0.8992    0.8944    0.8813      7062\n","\n","----------------------------------------------------------------------\n","[2022-08-28 21:04:03.683351] Epoch: 13, Step: 50/750, Avg. Running Loss: 0.041\n","[2022-08-28 21:05:24.211320] Epoch: 13, Step: 100/750, Avg. Running Loss: 0.040\n","[2022-08-28 21:06:44.775359] Epoch: 13, Step: 150/750, Avg. Running Loss: 0.044\n","[2022-08-28 21:08:05.501982] Epoch: 13, Step: 200/750, Avg. Running Loss: 0.045\n","[2022-08-28 21:09:26.145003] Epoch: 13, Step: 250/750, Avg. Running Loss: 0.035\n","[2022-08-28 21:10:46.680785] Epoch: 13, Step: 300/750, Avg. Running Loss: 0.047\n","[2022-08-28 21:12:07.148327] Epoch: 13, Step: 350/750, Avg. Running Loss: 0.042\n","[2022-08-28 21:13:27.898820] Epoch: 13, Step: 400/750, Avg. Running Loss: 0.038\n","[2022-08-28 21:14:48.699121] Epoch: 13, Step: 450/750, Avg. Running Loss: 0.041\n","[2022-08-28 21:16:09.202906] Epoch: 13, Step: 500/750, Avg. Running Loss: 0.043\n","[2022-08-28 21:17:29.732276] Epoch: 13, Step: 550/750, Avg. Running Loss: 0.040\n","[2022-08-28 21:18:50.008130] Epoch: 13, Step: 600/750, Avg. Running Loss: 0.037\n","[2022-08-28 21:20:10.686574] Epoch: 13, Step: 650/750, Avg. Running Loss: 0.034\n","[2022-08-28 21:21:30.837537] Epoch: 13, Step: 700/750, Avg. Running Loss: 0.036\n","[2022-08-28 21:22:51.577725] Epoch: 13, Step: 750/750, Avg. Running Loss: 0.042\n","----------------------------------------------------------------------\n","[2022-08-28 21:25:22.918654] Epoch: 13, Accuracy (Exact Match Ratio) Score=0.7345\n","[2022-08-28 21:25:22.918700] Epoch: 13, Hamming Loss=0.034025\n","[2022-08-28 21:25:22.918722] Epoch: 13, Classification Report:\n","                        precision    recall  f1-score   support\n","\n","Database_Administrator     0.9457    0.8825    0.9130       434\n","   Front_End_Developer     0.9026    0.8990    0.9008       505\n","        Java_Developer     0.8974    0.8462    0.8710       455\n"," Network_Administrator     0.9175    0.7942    0.8514       588\n","       Project_manager     0.9175    0.8920    0.9046       611\n","      Python_Developer     0.9526    0.9306    0.9415       389\n","      Security_Analyst     0.8983    0.8765    0.8873       413\n","    Software_Developer     0.9691    0.9545    0.9618      2002\n"," Systems_Administrator     0.9092    0.8346    0.8703       816\n","         Web_Developer     0.8079    0.8422    0.8247       849\n","\n","             micro avg     0.9174    0.8871    0.9020      7062\n","             macro avg     0.9118    0.8752    0.8926      7062\n","          weighted avg     0.9182    0.8871    0.9019      7062\n","           samples avg     0.9129    0.8904    0.8868      7062\n","\n","Validation Loss Decreased(0.034625--->0.034025) \t Saving The Model\n","----------------------------------------------------------------------\n","[2022-08-28 21:26:43.551834] Epoch: 14, Step: 50/750, Avg. Running Loss: 0.032\n","[2022-08-28 21:28:04.155094] Epoch: 14, Step: 100/750, Avg. Running Loss: 0.042\n","[2022-08-28 21:29:24.434876] Epoch: 14, Step: 150/750, Avg. Running Loss: 0.037\n","[2022-08-28 21:30:44.775898] Epoch: 14, Step: 200/750, Avg. Running Loss: 0.034\n","[2022-08-28 21:32:05.120175] Epoch: 14, Step: 250/750, Avg. Running Loss: 0.034\n","[2022-08-28 21:33:25.494627] Epoch: 14, Step: 300/750, Avg. Running Loss: 0.039\n","[2022-08-28 21:34:45.850342] Epoch: 14, Step: 350/750, Avg. Running Loss: 0.036\n","[2022-08-28 21:36:06.162072] Epoch: 14, Step: 400/750, Avg. Running Loss: 0.035\n","[2022-08-28 21:37:26.598196] Epoch: 14, Step: 450/750, Avg. Running Loss: 0.034\n","[2022-08-28 21:38:47.017583] Epoch: 14, Step: 500/750, Avg. Running Loss: 0.036\n","[2022-08-28 21:40:07.426471] Epoch: 14, Step: 550/750, Avg. Running Loss: 0.042\n","[2022-08-28 21:41:27.921870] Epoch: 14, Step: 600/750, Avg. Running Loss: 0.032\n","[2022-08-28 21:42:48.558650] Epoch: 14, Step: 650/750, Avg. Running Loss: 0.040\n","[2022-08-28 21:44:09.027093] Epoch: 14, Step: 700/750, Avg. Running Loss: 0.040\n","[2022-08-28 21:45:29.375603] Epoch: 14, Step: 750/750, Avg. Running Loss: 0.037\n","----------------------------------------------------------------------\n","[2022-08-28 21:47:58.855120] Epoch: 14, Accuracy (Exact Match Ratio) Score=0.72275\n","[2022-08-28 21:47:58.855165] Epoch: 14, Hamming Loss=0.036025\n","[2022-08-28 21:47:58.855186] Epoch: 14, Classification Report:\n","                        precision    recall  f1-score   support\n","\n","Database_Administrator     0.8884    0.8986    0.8935       434\n","   Front_End_Developer     0.8715    0.9129    0.8917       505\n","        Java_Developer     0.9270    0.8088    0.8638       455\n"," Network_Administrator     0.8256    0.8214    0.8235       588\n","       Project_manager     0.8927    0.8985    0.8956       611\n","      Python_Developer     0.9503    0.9332    0.9416       389\n","      Security_Analyst     0.8605    0.8959    0.8778       413\n","    Software_Developer     0.9749    0.9500    0.9623      2002\n"," Systems_Administrator     0.8994    0.8542    0.8762       816\n","         Web_Developer     0.8135    0.8528    0.8327       849\n","\n","             micro avg     0.9019    0.8931    0.8975      7062\n","             macro avg     0.8904    0.8826    0.8859      7062\n","          weighted avg     0.9034    0.8931    0.8977      7062\n","           samples avg     0.9019    0.8954    0.8831      7062\n","\n","----------------------------------------------------------------------\n","[2022-08-28 21:49:18.550151] Epoch: 15, Step: 50/750, Avg. Running Loss: 0.040\n","[2022-08-28 21:50:39.245731] Epoch: 15, Step: 100/750, Avg. Running Loss: 0.029\n","[2022-08-28 21:51:59.916706] Epoch: 15, Step: 150/750, Avg. Running Loss: 0.034\n","[2022-08-28 21:53:20.502858] Epoch: 15, Step: 200/750, Avg. Running Loss: 0.035\n","[2022-08-28 21:54:41.142795] Epoch: 15, Step: 250/750, Avg. Running Loss: 0.028\n","[2022-08-28 21:56:01.780907] Epoch: 15, Step: 300/750, Avg. Running Loss: 0.023\n","[2022-08-28 21:57:22.366142] Epoch: 15, Step: 350/750, Avg. Running Loss: 0.033\n","[2022-08-28 21:58:42.980765] Epoch: 15, Step: 400/750, Avg. Running Loss: 0.029\n","[2022-08-28 22:00:03.536449] Epoch: 15, Step: 450/750, Avg. Running Loss: 0.031\n","[2022-08-28 22:01:24.118005] Epoch: 15, Step: 500/750, Avg. Running Loss: 0.029\n","[2022-08-28 22:02:44.803253] Epoch: 15, Step: 550/750, Avg. Running Loss: 0.036\n","[2022-08-28 22:04:05.325614] Epoch: 15, Step: 600/750, Avg. Running Loss: 0.036\n","[2022-08-28 22:05:25.988711] Epoch: 15, Step: 650/750, Avg. Running Loss: 0.032\n","[2022-08-28 22:06:46.599038] Epoch: 15, Step: 700/750, Avg. Running Loss: 0.035\n","[2022-08-28 22:08:07.475303] Epoch: 15, Step: 750/750, Avg. Running Loss: 0.039\n","----------------------------------------------------------------------\n","[2022-08-28 22:10:37.959773] Epoch: 15, Accuracy (Exact Match Ratio) Score=0.712\n","[2022-08-28 22:10:37.959816] Epoch: 15, Hamming Loss=0.038175\n","[2022-08-28 22:10:37.959840] Epoch: 15, Classification Report:\n","                        precision    recall  f1-score   support\n","\n","Database_Administrator     0.8028    0.9101    0.8531       434\n","   Front_End_Developer     0.9000    0.9089    0.9044       505\n","        Java_Developer     0.8831    0.8637    0.8733       455\n"," Network_Administrator     0.8131    0.8214    0.8173       588\n","       Project_manager     0.8900    0.9002    0.8950       611\n","      Python_Developer     0.9359    0.9383    0.9371       389\n","      Security_Analyst     0.8529    0.8983    0.8750       413\n","    Software_Developer     0.9526    0.9630    0.9578      2002\n"," Systems_Administrator     0.8380    0.8750    0.8561       816\n","         Web_Developer     0.8526    0.8245    0.8383       849\n","\n","             micro avg     0.8854    0.9003    0.8928      7062\n","             macro avg     0.8721    0.8904    0.8808      7062\n","          weighted avg     0.8861    0.9003    0.8929      7062\n","           samples avg     0.8942    0.9028    0.8821      7062\n","\n","----------------------------------------------------------------------\n","[2022-08-28 22:11:57.223121] Epoch: 16, Step: 50/750, Avg. Running Loss: 0.030\n","[2022-08-28 22:13:17.517049] Epoch: 16, Step: 100/750, Avg. Running Loss: 0.024\n","[2022-08-28 22:14:37.939071] Epoch: 16, Step: 150/750, Avg. Running Loss: 0.029\n","[2022-08-28 22:15:57.968714] Epoch: 16, Step: 200/750, Avg. Running Loss: 0.029\n","[2022-08-28 22:17:18.161045] Epoch: 16, Step: 250/750, Avg. Running Loss: 0.037\n","[2022-08-28 22:18:38.533077] Epoch: 16, Step: 300/750, Avg. Running Loss: 0.031\n","[2022-08-28 22:19:59.044260] Epoch: 16, Step: 350/750, Avg. Running Loss: 0.027\n","[2022-08-28 22:21:19.240328] Epoch: 16, Step: 400/750, Avg. Running Loss: 0.026\n","[2022-08-28 22:22:39.695078] Epoch: 16, Step: 450/750, Avg. Running Loss: 0.027\n","[2022-08-28 22:24:00.147696] Epoch: 16, Step: 500/750, Avg. Running Loss: 0.033\n","[2022-08-28 22:25:20.305896] Epoch: 16, Step: 550/750, Avg. Running Loss: 0.028\n","[2022-08-28 22:26:40.533379] Epoch: 16, Step: 600/750, Avg. Running Loss: 0.034\n","[2022-08-28 22:28:01.023046] Epoch: 16, Step: 650/750, Avg. Running Loss: 0.030\n","[2022-08-28 22:29:21.535802] Epoch: 16, Step: 700/750, Avg. Running Loss: 0.023\n","[2022-08-28 22:30:42.216692] Epoch: 16, Step: 750/750, Avg. Running Loss: 0.028\n","----------------------------------------------------------------------\n","[2022-08-28 22:33:12.841770] Epoch: 16, Accuracy (Exact Match Ratio) Score=0.72325\n","[2022-08-28 22:33:12.841822] Epoch: 16, Hamming Loss=0.03525\n","[2022-08-28 22:33:12.841855] Epoch: 16, Classification Report:\n","                        precision    recall  f1-score   support\n","\n","Database_Administrator     0.8846    0.9009    0.8927       434\n","   Front_End_Developer     0.8943    0.9050    0.8996       505\n","        Java_Developer     0.8758    0.8835    0.8796       455\n"," Network_Administrator     0.9194    0.7959    0.8532       588\n","       Project_manager     0.9245    0.8822    0.9028       611\n","      Python_Developer     0.9621    0.9126    0.9367       389\n","      Security_Analyst     0.9538    0.8499    0.8988       413\n","    Software_Developer     0.9681    0.9550    0.9615      2002\n"," Systems_Administrator     0.9243    0.8235    0.8710       816\n","         Web_Developer     0.7508    0.8834    0.8117       849\n","\n","             micro avg     0.9071    0.8917    0.8993      7062\n","             macro avg     0.9058    0.8792    0.8908      7062\n","          weighted avg     0.9116    0.8917    0.9000      7062\n","           samples avg     0.9020    0.8918    0.8821      7062\n","\n","----------------------------------------------------------------------\n","[2022-08-28 22:34:32.666030] Epoch: 17, Step: 50/750, Avg. Running Loss: 0.028\n","[2022-08-28 22:35:53.290332] Epoch: 17, Step: 100/750, Avg. Running Loss: 0.027\n","[2022-08-28 22:37:13.655548] Epoch: 17, Step: 150/750, Avg. Running Loss: 0.024\n","[2022-08-28 22:38:34.014466] Epoch: 17, Step: 200/750, Avg. Running Loss: 0.024\n","[2022-08-28 22:39:54.647110] Epoch: 17, Step: 250/750, Avg. Running Loss: 0.027\n","[2022-08-28 22:41:15.490945] Epoch: 17, Step: 300/750, Avg. Running Loss: 0.023\n","[2022-08-28 22:42:35.988502] Epoch: 17, Step: 350/750, Avg. Running Loss: 0.027\n","[2022-08-28 22:43:56.256356] Epoch: 17, Step: 400/750, Avg. Running Loss: 0.024\n","[2022-08-28 22:45:16.592426] Epoch: 17, Step: 450/750, Avg. Running Loss: 0.029\n","[2022-08-28 22:46:36.732829] Epoch: 17, Step: 500/750, Avg. Running Loss: 0.026\n","[2022-08-28 22:47:56.868283] Epoch: 17, Step: 550/750, Avg. Running Loss: 0.023\n","[2022-08-28 22:49:17.314852] Epoch: 17, Step: 600/750, Avg. Running Loss: 0.021\n","[2022-08-28 22:50:37.940999] Epoch: 17, Step: 650/750, Avg. Running Loss: 0.021\n","[2022-08-28 22:51:58.104982] Epoch: 17, Step: 700/750, Avg. Running Loss: 0.028\n","[2022-08-28 22:53:18.553319] Epoch: 17, Step: 750/750, Avg. Running Loss: 0.028\n","----------------------------------------------------------------------\n","[2022-08-28 22:55:48.788245] Epoch: 17, Accuracy (Exact Match Ratio) Score=0.73925\n","[2022-08-28 22:55:48.788306] Epoch: 17, Hamming Loss=0.03345\n","[2022-08-28 22:55:48.788335] Epoch: 17, Classification Report:\n","                        precision    recall  f1-score   support\n","\n","Database_Administrator     0.8920    0.8940    0.8930       434\n","   Front_End_Developer     0.9256    0.8871    0.9060       505\n","        Java_Developer     0.9443    0.7824    0.8558       455\n"," Network_Administrator     0.8778    0.8061    0.8404       588\n","       Project_manager     0.9273    0.8773    0.9016       611\n","      Python_Developer     0.9482    0.9409    0.9445       389\n","      Security_Analyst     0.8828    0.8935    0.8881       413\n","    Software_Developer     0.9634    0.9590    0.9612      2002\n"," Systems_Administrator     0.9472    0.8137    0.8754       816\n","         Web_Developer     0.8817    0.8080    0.8433       849\n","\n","             micro avg     0.9278    0.8789    0.9027      7062\n","             macro avg     0.9190    0.8662    0.8909      7062\n","          weighted avg     0.9276    0.8789    0.9018      7062\n","           samples avg     0.9147    0.8843    0.8850      7062\n","\n","Validation Loss Decreased(0.034025--->0.033450) \t Saving The Model\n","----------------------------------------------------------------------\n","[2022-08-28 22:57:09.465446] Epoch: 18, Step: 50/750, Avg. Running Loss: 0.026\n","[2022-08-28 22:58:29.920582] Epoch: 18, Step: 100/750, Avg. Running Loss: 0.017\n","[2022-08-28 22:59:50.110107] Epoch: 18, Step: 150/750, Avg. Running Loss: 0.019\n","[2022-08-28 23:01:10.375770] Epoch: 18, Step: 200/750, Avg. Running Loss: 0.017\n","[2022-08-28 23:02:30.790889] Epoch: 18, Step: 250/750, Avg. Running Loss: 0.024\n","[2022-08-28 23:03:51.309190] Epoch: 18, Step: 300/750, Avg. Running Loss: 0.026\n","[2022-08-28 23:05:11.681795] Epoch: 18, Step: 350/750, Avg. Running Loss: 0.018\n","[2022-08-28 23:06:32.032327] Epoch: 18, Step: 400/750, Avg. Running Loss: 0.024\n","[2022-08-28 23:07:52.237281] Epoch: 18, Step: 450/750, Avg. Running Loss: 0.026\n","[2022-08-28 23:09:12.710536] Epoch: 18, Step: 500/750, Avg. Running Loss: 0.027\n","[2022-08-28 23:10:32.955996] Epoch: 18, Step: 550/750, Avg. Running Loss: 0.025\n","[2022-08-28 23:11:53.183431] Epoch: 18, Step: 600/750, Avg. Running Loss: 0.030\n","[2022-08-28 23:13:13.555582] Epoch: 18, Step: 650/750, Avg. Running Loss: 0.027\n","[2022-08-28 23:14:33.902443] Epoch: 18, Step: 700/750, Avg. Running Loss: 0.024\n","[2022-08-28 23:15:53.973654] Epoch: 18, Step: 750/750, Avg. Running Loss: 0.022\n","----------------------------------------------------------------------\n","[2022-08-28 23:18:24.119117] Epoch: 18, Accuracy (Exact Match Ratio) Score=0.7215\n","[2022-08-28 23:18:24.119153] Epoch: 18, Hamming Loss=0.036525\n","[2022-08-28 23:18:24.119172] Epoch: 18, Classification Report:\n","                        precision    recall  f1-score   support\n","\n","Database_Administrator     0.8812    0.9055    0.8932       434\n","   Front_End_Developer     0.8764    0.9129    0.8943       505\n","        Java_Developer     0.9260    0.7978    0.8571       455\n"," Network_Administrator     0.8518    0.8112    0.8310       588\n","       Project_manager     0.8861    0.8789    0.8825       611\n","      Python_Developer     0.9289    0.9409    0.9349       389\n","      Security_Analyst     0.8753    0.8838    0.8795       413\n","    Software_Developer     0.9686    0.9540    0.9612      2002\n"," Systems_Administrator     0.8573    0.8615    0.8594       816\n","         Web_Developer     0.8570    0.8257    0.8410       849\n","\n","             micro avg     0.9029    0.8887    0.8957      7062\n","             macro avg     0.8909    0.8772    0.8834      7062\n","          weighted avg     0.9031    0.8887    0.8955      7062\n","           samples avg     0.9018    0.8922    0.8821      7062\n","\n","----------------------------------------------------------------------\n","[2022-08-28 23:19:43.802928] Epoch: 19, Step: 50/750, Avg. Running Loss: 0.024\n","[2022-08-28 23:21:04.247551] Epoch: 19, Step: 100/750, Avg. Running Loss: 0.018\n","[2022-08-28 23:22:24.991265] Epoch: 19, Step: 150/750, Avg. Running Loss: 0.017\n","[2022-08-28 23:23:45.566804] Epoch: 19, Step: 200/750, Avg. Running Loss: 0.017\n","[2022-08-28 23:25:05.670263] Epoch: 19, Step: 250/750, Avg. Running Loss: 0.019\n","[2022-08-28 23:26:25.915062] Epoch: 19, Step: 300/750, Avg. Running Loss: 0.019\n","[2022-08-28 23:27:46.328705] Epoch: 19, Step: 350/750, Avg. Running Loss: 0.016\n","[2022-08-28 23:29:06.942860] Epoch: 19, Step: 400/750, Avg. Running Loss: 0.021\n","[2022-08-28 23:30:27.532126] Epoch: 19, Step: 450/750, Avg. Running Loss: 0.018\n","[2022-08-28 23:31:48.005489] Epoch: 19, Step: 500/750, Avg. Running Loss: 0.025\n","[2022-08-28 23:33:08.531070] Epoch: 19, Step: 550/750, Avg. Running Loss: 0.021\n","[2022-08-28 23:34:28.830784] Epoch: 19, Step: 600/750, Avg. Running Loss: 0.022\n","[2022-08-28 23:35:49.362553] Epoch: 19, Step: 650/750, Avg. Running Loss: 0.021\n","[2022-08-28 23:37:09.831410] Epoch: 19, Step: 700/750, Avg. Running Loss: 0.029\n","[2022-08-28 23:38:30.162588] Epoch: 19, Step: 750/750, Avg. Running Loss: 0.015\n","----------------------------------------------------------------------\n","[2022-08-28 23:41:00.034470] Epoch: 19, Accuracy (Exact Match Ratio) Score=0.722\n","[2022-08-28 23:41:00.034505] Epoch: 19, Hamming Loss=0.0363\n","[2022-08-28 23:41:00.034529] Epoch: 19, Classification Report:\n","                        precision    recall  f1-score   support\n","\n","Database_Administrator     0.8889    0.9032    0.8960       434\n","   Front_End_Developer     0.8855    0.9188    0.9018       505\n","        Java_Developer     0.9002    0.8330    0.8653       455\n"," Network_Administrator     0.8278    0.8095    0.8186       588\n","       Project_manager     0.8956    0.8985    0.8971       611\n","      Python_Developer     0.9500    0.9280    0.9389       389\n","      Security_Analyst     0.8897    0.8983    0.8940       413\n","    Software_Developer     0.9656    0.9535    0.9595      2002\n"," Systems_Administrator     0.8441    0.8627    0.8533       816\n","         Web_Developer     0.8540    0.8269    0.8402       849\n","\n","             micro avg     0.9005    0.8931    0.8968      7062\n","             macro avg     0.8901    0.8833    0.8865      7062\n","          weighted avg     0.9007    0.8931    0.8967      7062\n","           samples avg     0.9005    0.8954    0.8828      7062\n","\n","----------------------------------------------------------------------\n","[2022-08-28 23:42:19.410216] Epoch: 20, Step: 50/750, Avg. Running Loss: 0.020\n","[2022-08-28 23:43:39.709868] Epoch: 20, Step: 100/750, Avg. Running Loss: 0.017\n","[2022-08-28 23:45:00.141394] Epoch: 20, Step: 150/750, Avg. Running Loss: 0.017\n","[2022-08-28 23:46:20.879877] Epoch: 20, Step: 200/750, Avg. Running Loss: 0.018\n","[2022-08-28 23:47:41.668905] Epoch: 20, Step: 250/750, Avg. Running Loss: 0.013\n","[2022-08-28 23:49:01.975319] Epoch: 20, Step: 300/750, Avg. Running Loss: 0.021\n","[2022-08-28 23:50:21.980885] Epoch: 20, Step: 350/750, Avg. Running Loss: 0.014\n","[2022-08-28 23:51:42.452597] Epoch: 20, Step: 400/750, Avg. Running Loss: 0.020\n","[2022-08-28 23:53:03.067303] Epoch: 20, Step: 450/750, Avg. Running Loss: 0.019\n","[2022-08-28 23:54:23.704072] Epoch: 20, Step: 500/750, Avg. Running Loss: 0.015\n","[2022-08-28 23:55:44.548948] Epoch: 20, Step: 550/750, Avg. Running Loss: 0.014\n","[2022-08-28 23:57:05.016033] Epoch: 20, Step: 600/750, Avg. Running Loss: 0.018\n","[2022-08-28 23:58:25.426359] Epoch: 20, Step: 650/750, Avg. Running Loss: 0.017\n","[2022-08-28 23:59:45.834763] Epoch: 20, Step: 700/750, Avg. Running Loss: 0.024\n","[2022-08-29 00:01:06.602585] Epoch: 20, Step: 750/750, Avg. Running Loss: 0.019\n","----------------------------------------------------------------------\n","[2022-08-29 00:03:37.471444] Epoch: 20, Accuracy (Exact Match Ratio) Score=0.7135\n","[2022-08-29 00:03:37.471497] Epoch: 20, Hamming Loss=0.036925\n","[2022-08-29 00:03:37.471529] Epoch: 20, Classification Report:\n","                        precision    recall  f1-score   support\n","\n","Database_Administrator     0.8436    0.9194    0.8798       434\n","   Front_End_Developer     0.9078    0.8970    0.9024       505\n","        Java_Developer     0.8767    0.8593    0.8679       455\n"," Network_Administrator     0.8299    0.8129    0.8213       588\n","       Project_manager     0.9079    0.8871    0.8974       611\n","      Python_Developer     0.9455    0.9357    0.9406       389\n","      Security_Analyst     0.8186    0.8959    0.8555       413\n","    Software_Developer     0.9585    0.9585    0.9585      2002\n"," Systems_Administrator     0.8872    0.8480    0.8672       816\n","         Web_Developer     0.8386    0.8445    0.8415       849\n","\n","             micro avg     0.8953    0.8956    0.8954      7062\n","             macro avg     0.8814    0.8858    0.8832      7062\n","          weighted avg     0.8959    0.8956    0.8955      7062\n","           samples avg     0.8950    0.8978    0.8808      7062\n","\n","----------------------------------------------------------------------\n","[2022-08-29 00:04:57.209234] Epoch: 21, Step: 50/750, Avg. Running Loss: 0.020\n","[2022-08-29 00:06:17.979297] Epoch: 21, Step: 100/750, Avg. Running Loss: 0.013\n","[2022-08-29 00:07:38.382016] Epoch: 21, Step: 150/750, Avg. Running Loss: 0.016\n","[2022-08-29 00:08:59.037471] Epoch: 21, Step: 200/750, Avg. Running Loss: 0.018\n","[2022-08-29 00:10:19.655325] Epoch: 21, Step: 250/750, Avg. Running Loss: 0.016\n","[2022-08-29 00:11:40.295146] Epoch: 21, Step: 300/750, Avg. Running Loss: 0.017\n","[2022-08-29 00:13:00.975080] Epoch: 21, Step: 350/750, Avg. Running Loss: 0.019\n","[2022-08-29 00:14:21.704048] Epoch: 21, Step: 400/750, Avg. Running Loss: 0.018\n","[2022-08-29 00:15:42.539680] Epoch: 21, Step: 450/750, Avg. Running Loss: 0.017\n","[2022-08-29 00:17:03.014922] Epoch: 21, Step: 500/750, Avg. Running Loss: 0.019\n","[2022-08-29 00:18:23.445486] Epoch: 21, Step: 550/750, Avg. Running Loss: 0.017\n","[2022-08-29 00:19:44.222361] Epoch: 21, Step: 600/750, Avg. Running Loss: 0.018\n","[2022-08-29 00:21:04.749309] Epoch: 21, Step: 650/750, Avg. Running Loss: 0.016\n","[2022-08-29 00:22:25.058345] Epoch: 21, Step: 700/750, Avg. Running Loss: 0.013\n","[2022-08-29 00:23:45.626921] Epoch: 21, Step: 750/750, Avg. Running Loss: 0.018\n","----------------------------------------------------------------------\n","[2022-08-29 00:26:16.422699] Epoch: 21, Accuracy (Exact Match Ratio) Score=0.71325\n","[2022-08-29 00:26:16.422747] Epoch: 21, Hamming Loss=0.037475\n","[2022-08-29 00:26:16.422790] Epoch: 21, Classification Report:\n","                        precision    recall  f1-score   support\n","\n","Database_Administrator     0.8653    0.9032    0.8839       434\n","   Front_End_Developer     0.8959    0.9030    0.8994       505\n","        Java_Developer     0.8897    0.8505    0.8697       455\n"," Network_Administrator     0.8310    0.8197    0.8253       588\n","       Project_manager     0.8974    0.9018    0.8996       611\n","      Python_Developer     0.9383    0.9383    0.9383       389\n","      Security_Analyst     0.8768    0.8789    0.8779       413\n","    Software_Developer     0.9691    0.9560    0.9625      2002\n"," Systems_Administrator     0.8156    0.8725    0.8431       816\n","         Web_Developer     0.8288    0.8327    0.8308       849\n","\n","             micro avg     0.8920    0.8962    0.8941      7062\n","             macro avg     0.8808    0.8857    0.8830      7062\n","          weighted avg     0.8930    0.8962    0.8944      7062\n","           samples avg     0.8936    0.8982    0.8804      7062\n","\n","----------------------------------------------------------------------\n","[2022-08-29 00:27:36.065020] Epoch: 22, Step: 50/750, Avg. Running Loss: 0.019\n","[2022-08-29 00:28:56.242782] Epoch: 22, Step: 100/750, Avg. Running Loss: 0.011\n","[2022-08-29 00:30:16.451572] Epoch: 22, Step: 150/750, Avg. Running Loss: 0.012\n","[2022-08-29 00:31:37.075489] Epoch: 22, Step: 200/750, Avg. Running Loss: 0.014\n","[2022-08-29 00:32:57.602442] Epoch: 22, Step: 250/750, Avg. Running Loss: 0.010\n","[2022-08-29 00:34:18.142974] Epoch: 22, Step: 300/750, Avg. Running Loss: 0.019\n","[2022-08-29 00:35:38.318364] Epoch: 22, Step: 350/750, Avg. Running Loss: 0.013\n","[2022-08-29 00:36:58.578638] Epoch: 22, Step: 400/750, Avg. Running Loss: 0.014\n","[2022-08-29 00:38:18.816067] Epoch: 22, Step: 450/750, Avg. Running Loss: 0.012\n","[2022-08-29 00:39:39.491873] Epoch: 22, Step: 500/750, Avg. Running Loss: 0.020\n","[2022-08-29 00:41:00.101086] Epoch: 22, Step: 550/750, Avg. Running Loss: 0.015\n","[2022-08-29 00:42:20.541302] Epoch: 22, Step: 600/750, Avg. Running Loss: 0.018\n","[2022-08-29 00:43:41.234816] Epoch: 22, Step: 650/750, Avg. Running Loss: 0.014\n","[2022-08-29 00:45:02.102827] Epoch: 22, Step: 700/750, Avg. Running Loss: 0.016\n","[2022-08-29 00:46:22.622554] Epoch: 22, Step: 750/750, Avg. Running Loss: 0.013\n","----------------------------------------------------------------------\n","[2022-08-29 00:48:52.309165] Epoch: 22, Accuracy (Exact Match Ratio) Score=0.714\n","[2022-08-29 00:48:52.309209] Epoch: 22, Hamming Loss=0.036575\n","[2022-08-29 00:48:52.309232] Epoch: 22, Classification Report:\n","                        precision    recall  f1-score   support\n","\n","Database_Administrator     0.9238    0.8940    0.9087       434\n","   Front_End_Developer     0.8798    0.9129    0.8960       505\n","        Java_Developer     0.8825    0.8418    0.8616       455\n"," Network_Administrator     0.8229    0.8299    0.8264       588\n","       Project_manager     0.8905    0.9051    0.8977       611\n","      Python_Developer     0.9381    0.9357    0.9369       389\n","      Security_Analyst     0.9184    0.8717    0.8944       413\n","    Software_Developer     0.9493    0.9635    0.9564      2002\n"," Systems_Administrator     0.8924    0.8542    0.8729       816\n","         Web_Developer     0.7918    0.8598    0.8244       849\n","\n","             micro avg     0.8939    0.8996    0.8967      7062\n","             macro avg     0.8890    0.8869    0.8875      7062\n","          weighted avg     0.8949    0.8996    0.8969      7062\n","           samples avg     0.8940    0.8995    0.8815      7062\n","\n","----------------------------------------------------------------------\n","[2022-08-29 00:50:12.126629] Epoch: 23, Step: 50/750, Avg. Running Loss: 0.015\n","[2022-08-29 00:51:32.578110] Epoch: 23, Step: 100/750, Avg. Running Loss: 0.014\n","[2022-08-29 00:52:52.958394] Epoch: 23, Step: 150/750, Avg. Running Loss: 0.011\n","[2022-08-29 00:54:13.445442] Epoch: 23, Step: 200/750, Avg. Running Loss: 0.016\n","[2022-08-29 00:55:34.119563] Epoch: 23, Step: 250/750, Avg. Running Loss: 0.014\n","[2022-08-29 00:56:54.539137] Epoch: 23, Step: 300/750, Avg. Running Loss: 0.017\n","[2022-08-29 00:58:14.960808] Epoch: 23, Step: 350/750, Avg. Running Loss: 0.011\n","[2022-08-29 00:59:35.409454] Epoch: 23, Step: 400/750, Avg. Running Loss: 0.016\n","[2022-08-29 01:00:55.861807] Epoch: 23, Step: 450/750, Avg. Running Loss: 0.015\n","[2022-08-29 01:02:16.304598] Epoch: 23, Step: 500/750, Avg. Running Loss: 0.013\n","[2022-08-29 01:03:36.684857] Epoch: 23, Step: 550/750, Avg. Running Loss: 0.015\n","[2022-08-29 01:04:56.989441] Epoch: 23, Step: 600/750, Avg. Running Loss: 0.017\n","[2022-08-29 01:06:17.520645] Epoch: 23, Step: 650/750, Avg. Running Loss: 0.012\n","[2022-08-29 01:07:38.320560] Epoch: 23, Step: 700/750, Avg. Running Loss: 0.009\n","[2022-08-29 01:08:58.936715] Epoch: 23, Step: 750/750, Avg. Running Loss: 0.015\n","----------------------------------------------------------------------\n","[2022-08-29 01:11:29.159092] Epoch: 23, Accuracy (Exact Match Ratio) Score=0.72775\n","[2022-08-29 01:11:29.159131] Epoch: 23, Hamming Loss=0.035475\n","[2022-08-29 01:11:29.159146] Epoch: 23, Classification Report:\n","                        precision    recall  f1-score   support\n","\n","Database_Administrator     0.9282    0.8940    0.9108       434\n","   Front_End_Developer     0.9066    0.9030    0.9048       505\n","        Java_Developer     0.9054    0.8418    0.8724       455\n"," Network_Administrator     0.8577    0.8095    0.8329       588\n","       Project_manager     0.8846    0.9034    0.8939       611\n","      Python_Developer     0.9404    0.9332    0.9368       389\n","      Security_Analyst     0.9020    0.8692    0.8853       413\n","    Software_Developer     0.9619    0.9580    0.9600      2002\n"," Systems_Administrator     0.8858    0.8652    0.8754       816\n","         Web_Developer     0.7998    0.8469    0.8227       849\n","\n","             micro avg     0.9032    0.8949    0.8991      7062\n","             macro avg     0.8972    0.8824    0.8895      7062\n","          weighted avg     0.9039    0.8949    0.8991      7062\n","           samples avg     0.9011    0.8967    0.8842      7062\n","\n","----------------------------------------------------------------------\n","[2022-08-29 01:12:48.845260] Epoch: 24, Step: 50/750, Avg. Running Loss: 0.008\n","[2022-08-29 01:14:09.347150] Epoch: 24, Step: 100/750, Avg. Running Loss: 0.011\n","[2022-08-29 01:15:29.763046] Epoch: 24, Step: 150/750, Avg. Running Loss: 0.011\n","[2022-08-29 01:16:50.154695] Epoch: 24, Step: 200/750, Avg. Running Loss: 0.012\n","[2022-08-29 01:18:10.833465] Epoch: 24, Step: 250/750, Avg. Running Loss: 0.012\n","[2022-08-29 01:19:31.457553] Epoch: 24, Step: 300/750, Avg. Running Loss: 0.010\n","[2022-08-29 01:20:51.868721] Epoch: 24, Step: 350/750, Avg. Running Loss: 0.016\n","[2022-08-29 01:22:12.253138] Epoch: 24, Step: 400/750, Avg. Running Loss: 0.009\n","[2022-08-29 01:23:32.480757] Epoch: 24, Step: 450/750, Avg. Running Loss: 0.010\n","[2022-08-29 01:24:52.664961] Epoch: 24, Step: 500/750, Avg. Running Loss: 0.011\n","[2022-08-29 01:26:12.933059] Epoch: 24, Step: 550/750, Avg. Running Loss: 0.011\n","[2022-08-29 01:27:33.119808] Epoch: 24, Step: 600/750, Avg. Running Loss: 0.016\n","[2022-08-29 01:28:53.605042] Epoch: 24, Step: 650/750, Avg. Running Loss: 0.011\n","[2022-08-29 01:30:14.305705] Epoch: 24, Step: 700/750, Avg. Running Loss: 0.015\n","[2022-08-29 01:31:34.684145] Epoch: 24, Step: 750/750, Avg. Running Loss: 0.013\n","----------------------------------------------------------------------\n","[2022-08-29 01:34:04.519836] Epoch: 24, Accuracy (Exact Match Ratio) Score=0.7375\n","[2022-08-29 01:34:04.519878] Epoch: 24, Hamming Loss=0.0341\n","[2022-08-29 01:34:04.519906] Epoch: 24, Classification Report:\n","                        precision    recall  f1-score   support\n","\n","Database_Administrator     0.9161    0.9055    0.9108       434\n","   Front_End_Developer     0.9064    0.9010    0.9037       505\n","        Java_Developer     0.9104    0.8484    0.8783       455\n"," Network_Administrator     0.8525    0.8061    0.8287       588\n","       Project_manager     0.9147    0.8773    0.8956       611\n","      Python_Developer     0.9600    0.9254    0.9424       389\n","      Security_Analyst     0.9312    0.8523    0.8900       413\n","    Software_Developer     0.9668    0.9590    0.9629      2002\n"," Systems_Administrator     0.9098    0.8529    0.8805       816\n","         Web_Developer     0.8121    0.8504    0.8308       849\n","\n","             micro avg     0.9135    0.8912    0.9022      7062\n","             macro avg     0.9080    0.8778    0.8924      7062\n","          weighted avg     0.9141    0.8912    0.9022      7062\n","           samples avg     0.9059    0.8928    0.8851      7062\n","\n","----------------------------------------------------------------------\n","[2022-08-29 01:35:24.110786] Epoch: 25, Step: 50/750, Avg. Running Loss: 0.009\n","[2022-08-29 01:36:44.361267] Epoch: 25, Step: 100/750, Avg. Running Loss: 0.012\n","[2022-08-29 01:38:04.809932] Epoch: 25, Step: 150/750, Avg. Running Loss: 0.011\n","[2022-08-29 01:39:25.407111] Epoch: 25, Step: 200/750, Avg. Running Loss: 0.011\n","[2022-08-29 01:40:45.876501] Epoch: 25, Step: 250/750, Avg. Running Loss: 0.014\n","[2022-08-29 01:42:06.278421] Epoch: 25, Step: 300/750, Avg. Running Loss: 0.009\n","[2022-08-29 01:43:26.602744] Epoch: 25, Step: 350/750, Avg. Running Loss: 0.010\n","[2022-08-29 01:44:46.865884] Epoch: 25, Step: 400/750, Avg. Running Loss: 0.013\n","[2022-08-29 01:46:07.176178] Epoch: 25, Step: 450/750, Avg. Running Loss: 0.007\n","[2022-08-29 01:47:27.280166] Epoch: 25, Step: 500/750, Avg. Running Loss: 0.010\n","[2022-08-29 01:48:47.541071] Epoch: 25, Step: 550/750, Avg. Running Loss: 0.013\n","[2022-08-29 01:50:07.957901] Epoch: 25, Step: 600/750, Avg. Running Loss: 0.011\n","[2022-08-29 01:51:28.293086] Epoch: 25, Step: 650/750, Avg. Running Loss: 0.014\n","[2022-08-29 01:52:48.836199] Epoch: 25, Step: 700/750, Avg. Running Loss: 0.013\n","[2022-08-29 01:54:09.121818] Epoch: 25, Step: 750/750, Avg. Running Loss: 0.009\n","----------------------------------------------------------------------\n","[2022-08-29 01:56:38.465541] Epoch: 25, Accuracy (Exact Match Ratio) Score=0.7265\n","[2022-08-29 01:56:38.465579] Epoch: 25, Hamming Loss=0.03565\n","[2022-08-29 01:56:38.465593] Epoch: 25, Classification Report:\n","                        precision    recall  f1-score   support\n","\n","Database_Administrator     0.8834    0.9078    0.8955       434\n","   Front_End_Developer     0.9140    0.9050    0.9095       505\n","        Java_Developer     0.8692    0.8615    0.8653       455\n"," Network_Administrator     0.8559    0.8180    0.8365       588\n","       Project_manager     0.8762    0.9034    0.8896       611\n","      Python_Developer     0.9404    0.9332    0.9368       389\n","      Security_Analyst     0.8873    0.8765    0.8819       413\n","    Software_Developer     0.9634    0.9590    0.9612      2002\n"," Systems_Administrator     0.8933    0.8615    0.8771       816\n","         Web_Developer     0.8051    0.8563    0.8299       849\n","\n","             micro avg     0.8988    0.8993    0.8991      7062\n","             macro avg     0.8888    0.8882    0.8883      7062\n","          weighted avg     0.8995    0.8993    0.8992      7062\n","           samples avg     0.8999    0.9005    0.8851      7062\n","\n","----------------------------------------------------------------------\n","[2022-08-29 01:57:58.005133] Epoch: 26, Step: 50/750, Avg. Running Loss: 0.011\n","[2022-08-29 01:59:18.521026] Epoch: 26, Step: 100/750, Avg. Running Loss: 0.011\n","[2022-08-29 02:00:39.099432] Epoch: 26, Step: 150/750, Avg. Running Loss: 0.009\n","[2022-08-29 02:01:59.704650] Epoch: 26, Step: 200/750, Avg. Running Loss: 0.008\n","[2022-08-29 02:03:20.106686] Epoch: 26, Step: 250/750, Avg. Running Loss: 0.008\n","[2022-08-29 02:04:40.692455] Epoch: 26, Step: 300/750, Avg. Running Loss: 0.011\n","[2022-08-29 02:06:01.306640] Epoch: 26, Step: 350/750, Avg. Running Loss: 0.012\n","[2022-08-29 02:07:21.813235] Epoch: 26, Step: 400/750, Avg. Running Loss: 0.005\n","[2022-08-29 02:08:42.431413] Epoch: 26, Step: 450/750, Avg. Running Loss: 0.011\n","[2022-08-29 02:10:02.795992] Epoch: 26, Step: 500/750, Avg. Running Loss: 0.010\n","[2022-08-29 02:11:23.247712] Epoch: 26, Step: 550/750, Avg. Running Loss: 0.008\n","[2022-08-29 02:12:43.810063] Epoch: 26, Step: 600/750, Avg. Running Loss: 0.011\n","[2022-08-29 02:14:04.386847] Epoch: 26, Step: 650/750, Avg. Running Loss: 0.009\n","[2022-08-29 02:15:24.772348] Epoch: 26, Step: 700/750, Avg. Running Loss: 0.012\n","[2022-08-29 02:16:45.187185] Epoch: 26, Step: 750/750, Avg. Running Loss: 0.009\n","----------------------------------------------------------------------\n","[2022-08-29 02:19:13.857212] Epoch: 26, Accuracy (Exact Match Ratio) Score=0.742\n","[2022-08-29 02:19:13.857270] Epoch: 26, Hamming Loss=0.03345\n","[2022-08-29 02:19:13.857308] Epoch: 26, Classification Report:\n","                        precision    recall  f1-score   support\n","\n","Database_Administrator     0.9074    0.9032    0.9053       434\n","   Front_End_Developer     0.8919    0.9149    0.9032       505\n","        Java_Developer     0.9137    0.8374    0.8739       455\n"," Network_Administrator     0.9110    0.8010    0.8525       588\n","       Project_manager     0.9068    0.8920    0.8993       611\n","      Python_Developer     0.9478    0.9332    0.9404       389\n","      Security_Analyst     0.8840    0.8668    0.8753       413\n","    Software_Developer     0.9696    0.9570    0.9633      2002\n"," Systems_Administrator     0.9126    0.8444    0.8771       816\n","         Web_Developer     0.8361    0.8410    0.8385       849\n","\n","             micro avg     0.9173    0.8908    0.9039      7062\n","             macro avg     0.9081    0.8791    0.8929      7062\n","          weighted avg     0.9175    0.8908    0.9036      7062\n","           samples avg     0.9079    0.8927    0.8863      7062\n","\n","----------------------------------------------------------------------\n","[2022-08-29 02:20:33.349931] Epoch: 27, Step: 50/750, Avg. Running Loss: 0.007\n","[2022-08-29 02:21:53.969138] Epoch: 27, Step: 100/750, Avg. Running Loss: 0.008\n","[2022-08-29 02:23:14.584069] Epoch: 27, Step: 150/750, Avg. Running Loss: 0.013\n","[2022-08-29 02:24:35.119401] Epoch: 27, Step: 200/750, Avg. Running Loss: 0.011\n","[2022-08-29 02:25:55.688346] Epoch: 27, Step: 250/750, Avg. Running Loss: 0.009\n","[2022-08-29 02:27:16.371752] Epoch: 27, Step: 300/750, Avg. Running Loss: 0.009\n","[2022-08-29 02:28:36.885169] Epoch: 27, Step: 350/750, Avg. Running Loss: 0.009\n","[2022-08-29 02:29:57.552218] Epoch: 27, Step: 400/750, Avg. Running Loss: 0.007\n","[2022-08-29 02:31:18.271170] Epoch: 27, Step: 450/750, Avg. Running Loss: 0.007\n","[2022-08-29 02:32:39.063655] Epoch: 27, Step: 500/750, Avg. Running Loss: 0.010\n","[2022-08-29 02:33:59.907179] Epoch: 27, Step: 550/750, Avg. Running Loss: 0.012\n","[2022-08-29 02:35:20.435196] Epoch: 27, Step: 600/750, Avg. Running Loss: 0.008\n","[2022-08-29 02:36:41.013217] Epoch: 27, Step: 650/750, Avg. Running Loss: 0.010\n","[2022-08-29 02:38:01.548964] Epoch: 27, Step: 700/750, Avg. Running Loss: 0.009\n","[2022-08-29 02:39:21.972626] Epoch: 27, Step: 750/750, Avg. Running Loss: 0.007\n","----------------------------------------------------------------------\n","[2022-08-29 02:41:50.731241] Epoch: 27, Accuracy (Exact Match Ratio) Score=0.737\n","[2022-08-29 02:41:50.731278] Epoch: 27, Hamming Loss=0.0341\n","[2022-08-29 02:41:50.731292] Epoch: 27, Classification Report:\n","                        precision    recall  f1-score   support\n","\n","Database_Administrator     0.9202    0.9032    0.9116       434\n","   Front_End_Developer     0.8969    0.9129    0.9048       505\n","        Java_Developer     0.9352    0.7934    0.8585       455\n"," Network_Administrator     0.8354    0.8197    0.8275       588\n","       Project_manager     0.9123    0.8854    0.8987       611\n","      Python_Developer     0.9472    0.9229    0.9349       389\n","      Security_Analyst     0.8605    0.8959    0.8778       413\n","    Software_Developer     0.9764    0.9525    0.9643      2002\n"," Systems_Administrator     0.9114    0.8444    0.8766       816\n","         Web_Developer     0.8703    0.8139    0.8411       849\n","\n","             micro avg     0.9185    0.8854    0.9017      7062\n","             macro avg     0.9066    0.8744    0.8896      7062\n","          weighted avg     0.9187    0.8854    0.9013      7062\n","           samples avg     0.9123    0.8903    0.8862      7062\n","\n","----------------------------------------------------------------------\n","[2022-08-29 02:43:10.455695] Epoch: 28, Step: 50/750, Avg. Running Loss: 0.005\n","[2022-08-29 02:44:30.956115] Epoch: 28, Step: 100/750, Avg. Running Loss: 0.006\n","[2022-08-29 02:45:51.389559] Epoch: 28, Step: 150/750, Avg. Running Loss: 0.006\n","[2022-08-29 02:47:11.934951] Epoch: 28, Step: 200/750, Avg. Running Loss: 0.008\n","[2022-08-29 02:48:32.534201] Epoch: 28, Step: 250/750, Avg. Running Loss: 0.009\n","[2022-08-29 02:49:53.132726] Epoch: 28, Step: 300/750, Avg. Running Loss: 0.006\n","[2022-08-29 02:51:13.798478] Epoch: 28, Step: 350/750, Avg. Running Loss: 0.010\n","[2022-08-29 02:52:34.459814] Epoch: 28, Step: 400/750, Avg. Running Loss: 0.011\n","[2022-08-29 02:53:55.135625] Epoch: 28, Step: 450/750, Avg. Running Loss: 0.006\n","[2022-08-29 02:55:15.912336] Epoch: 28, Step: 500/750, Avg. Running Loss: 0.006\n","[2022-08-29 02:56:36.493534] Epoch: 28, Step: 550/750, Avg. Running Loss: 0.008\n","[2022-08-29 02:57:56.696973] Epoch: 28, Step: 600/750, Avg. Running Loss: 0.005\n","[2022-08-29 02:59:17.176078] Epoch: 28, Step: 650/750, Avg. Running Loss: 0.006\n","[2022-08-29 03:00:37.816030] Epoch: 28, Step: 700/750, Avg. Running Loss: 0.009\n","[2022-08-29 03:01:58.599194] Epoch: 28, Step: 750/750, Avg. Running Loss: 0.008\n","----------------------------------------------------------------------\n","[2022-08-29 03:04:27.939174] Epoch: 28, Accuracy (Exact Match Ratio) Score=0.74275\n","[2022-08-29 03:04:27.939211] Epoch: 28, Hamming Loss=0.03325\n","[2022-08-29 03:04:27.939225] Epoch: 28, Classification Report:\n","                        precision    recall  f1-score   support\n","\n","Database_Administrator     0.9236    0.8917    0.9074       434\n","   Front_End_Developer     0.8872    0.9030    0.8950       505\n","        Java_Developer     0.9167    0.8462    0.8800       455\n"," Network_Administrator     0.8879    0.8078    0.8459       588\n","       Project_manager     0.9162    0.8773    0.8963       611\n","      Python_Developer     0.9524    0.9254    0.9387       389\n","      Security_Analyst     0.8687    0.8814    0.8750       413\n","    Software_Developer     0.9799    0.9510    0.9653      2002\n"," Systems_Administrator     0.9267    0.8370    0.8796       816\n","         Web_Developer     0.8593    0.8198    0.8391       849\n","\n","             micro avg     0.9240    0.8845    0.9038      7062\n","             macro avg     0.9119    0.8741    0.8922      7062\n","          weighted avg     0.9239    0.8845    0.9035      7062\n","           samples avg     0.9126    0.8884    0.8863      7062\n","\n","Validation Loss Decreased(0.033450--->0.033250) \t Saving The Model\n","----------------------------------------------------------------------\n","[2022-08-29 03:05:48.678928] Epoch: 29, Step: 50/750, Avg. Running Loss: 0.006\n","[2022-08-29 03:07:09.485992] Epoch: 29, Step: 100/750, Avg. Running Loss: 0.007\n","[2022-08-29 03:08:30.284361] Epoch: 29, Step: 150/750, Avg. Running Loss: 0.009\n","[2022-08-29 03:09:50.897740] Epoch: 29, Step: 200/750, Avg. Running Loss: 0.005\n","[2022-08-29 03:11:11.270254] Epoch: 29, Step: 250/750, Avg. Running Loss: 0.006\n","[2022-08-29 03:12:32.133455] Epoch: 29, Step: 300/750, Avg. Running Loss: 0.007\n","[2022-08-29 03:13:52.799150] Epoch: 29, Step: 350/750, Avg. Running Loss: 0.006\n","[2022-08-29 03:15:13.597066] Epoch: 29, Step: 400/750, Avg. Running Loss: 0.007\n","[2022-08-29 03:16:34.243188] Epoch: 29, Step: 450/750, Avg. Running Loss: 0.006\n","[2022-08-29 03:17:54.818499] Epoch: 29, Step: 500/750, Avg. Running Loss: 0.005\n","[2022-08-29 03:19:15.364257] Epoch: 29, Step: 550/750, Avg. Running Loss: 0.008\n","[2022-08-29 03:20:36.090335] Epoch: 29, Step: 600/750, Avg. Running Loss: 0.007\n","[2022-08-29 03:21:56.491832] Epoch: 29, Step: 650/750, Avg. Running Loss: 0.008\n","[2022-08-29 03:23:16.833259] Epoch: 29, Step: 700/750, Avg. Running Loss: 0.005\n","[2022-08-29 03:24:37.076190] Epoch: 29, Step: 750/750, Avg. Running Loss: 0.007\n","----------------------------------------------------------------------\n","[2022-08-29 03:27:06.167010] Epoch: 29, Accuracy (Exact Match Ratio) Score=0.7185\n","[2022-08-29 03:27:06.167046] Epoch: 29, Hamming Loss=0.036475\n","[2022-08-29 03:27:06.167060] Epoch: 29, Classification Report:\n","                        precision    recall  f1-score   support\n","\n","Database_Administrator     0.8501    0.9147    0.8812       434\n","   Front_End_Developer     0.8956    0.9168    0.9061       505\n","        Java_Developer     0.8907    0.8593    0.8747       455\n"," Network_Administrator     0.8851    0.7993    0.8400       588\n","       Project_manager     0.8567    0.8903    0.8732       611\n","      Python_Developer     0.9404    0.9332    0.9368       389\n","      Security_Analyst     0.8875    0.8789    0.8832       413\n","    Software_Developer     0.9644    0.9595    0.9619      2002\n"," Systems_Administrator     0.8577    0.8640    0.8608       816\n","         Web_Developer     0.8218    0.8528    0.8370       849\n","\n","             micro avg     0.8957    0.8979    0.8968      7062\n","             macro avg     0.8850    0.8869    0.8855      7062\n","          weighted avg     0.8965    0.8979    0.8968      7062\n","           samples avg     0.8943    0.8986    0.8810      7062\n","\n","----------------------------------------------------------------------\n","[2022-08-29 03:28:25.928348] Epoch: 30, Step: 50/750, Avg. Running Loss: 0.004\n","[2022-08-29 03:29:46.342838] Epoch: 30, Step: 100/750, Avg. Running Loss: 0.005\n","[2022-08-29 03:31:06.435359] Epoch: 30, Step: 150/750, Avg. Running Loss: 0.006\n","[2022-08-29 03:32:26.569183] Epoch: 30, Step: 200/750, Avg. Running Loss: 0.007\n","[2022-08-29 03:33:46.815329] Epoch: 30, Step: 250/750, Avg. Running Loss: 0.009\n","[2022-08-29 03:35:07.203832] Epoch: 30, Step: 300/750, Avg. Running Loss: 0.008\n","[2022-08-29 03:36:27.774097] Epoch: 30, Step: 350/750, Avg. Running Loss: 0.006\n","[2022-08-29 03:37:48.343148] Epoch: 30, Step: 400/750, Avg. Running Loss: 0.005\n","[2022-08-29 03:39:08.912236] Epoch: 30, Step: 450/750, Avg. Running Loss: 0.009\n","[2022-08-29 03:40:29.549901] Epoch: 30, Step: 500/750, Avg. Running Loss: 0.006\n","[2022-08-29 03:41:50.214013] Epoch: 30, Step: 550/750, Avg. Running Loss: 0.008\n","[2022-08-29 03:43:10.309865] Epoch: 30, Step: 600/750, Avg. Running Loss: 0.008\n","[2022-08-29 03:44:30.391236] Epoch: 30, Step: 650/750, Avg. Running Loss: 0.007\n","[2022-08-29 03:45:50.700534] Epoch: 30, Step: 700/750, Avg. Running Loss: 0.007\n","[2022-08-29 03:47:10.744036] Epoch: 30, Step: 750/750, Avg. Running Loss: 0.008\n","----------------------------------------------------------------------\n","[2022-08-29 03:49:39.062679] Epoch: 30, Accuracy (Exact Match Ratio) Score=0.73225\n","[2022-08-29 03:49:39.062722] Epoch: 30, Hamming Loss=0.0348\n","[2022-08-29 03:49:39.062744] Epoch: 30, Classification Report:\n","                        precision    recall  f1-score   support\n","\n","Database_Administrator     0.8891    0.9055    0.8973       434\n","   Front_End_Developer     0.8953    0.9149    0.9050       505\n","        Java_Developer     0.8982    0.8725    0.8852       455\n"," Network_Administrator     0.8569    0.8146    0.8352       588\n","       Project_manager     0.8752    0.8953    0.8851       611\n","      Python_Developer     0.9125    0.9383    0.9252       389\n","      Security_Analyst     0.8905    0.8668    0.8785       413\n","    Software_Developer     0.9673    0.9610    0.9642      2002\n"," Systems_Administrator     0.8775    0.8603    0.8688       816\n","         Web_Developer     0.8556    0.8375    0.8464       849\n","\n","             micro avg     0.9047    0.8975    0.9011      7062\n","             macro avg     0.8918    0.8867    0.8891      7062\n","          weighted avg     0.9044    0.8975    0.9008      7062\n","           samples avg     0.9032    0.8984    0.8861      7062\n","\n","----------------------------------------------------------------------\n","[2022-08-29 03:50:58.491678] Epoch: 31, Step: 50/750, Avg. Running Loss: 0.008\n","[2022-08-29 03:52:18.868602] Epoch: 31, Step: 100/750, Avg. Running Loss: 0.005\n","[2022-08-29 03:53:39.145383] Epoch: 31, Step: 150/750, Avg. Running Loss: 0.005\n","[2022-08-29 03:54:59.779795] Epoch: 31, Step: 200/750, Avg. Running Loss: 0.004\n","[2022-08-29 03:56:20.349128] Epoch: 31, Step: 250/750, Avg. Running Loss: 0.004\n","[2022-08-29 03:57:40.924206] Epoch: 31, Step: 300/750, Avg. Running Loss: 0.006\n","[2022-08-29 03:59:01.475266] Epoch: 31, Step: 350/750, Avg. Running Loss: 0.008\n","[2022-08-29 04:00:22.172110] Epoch: 31, Step: 400/750, Avg. Running Loss: 0.007\n","[2022-08-29 04:01:42.782917] Epoch: 31, Step: 450/750, Avg. Running Loss: 0.005\n","[2022-08-29 04:03:03.125602] Epoch: 31, Step: 500/750, Avg. Running Loss: 0.008\n","[2022-08-29 04:04:23.275451] Epoch: 31, Step: 550/750, Avg. Running Loss: 0.005\n","[2022-08-29 04:05:43.477183] Epoch: 31, Step: 600/750, Avg. Running Loss: 0.007\n","[2022-08-29 04:07:03.956090] Epoch: 31, Step: 650/750, Avg. Running Loss: 0.007\n","[2022-08-29 04:08:24.507527] Epoch: 31, Step: 700/750, Avg. Running Loss: 0.008\n","[2022-08-29 04:09:44.785142] Epoch: 31, Step: 750/750, Avg. Running Loss: 0.017\n","----------------------------------------------------------------------\n","[2022-08-29 04:12:12.331265] Epoch: 31, Accuracy (Exact Match Ratio) Score=0.70275\n","[2022-08-29 04:12:12.331313] Epoch: 31, Hamming Loss=0.0389\n","[2022-08-29 04:12:12.331338] Epoch: 31, Classification Report:\n","                        precision    recall  f1-score   support\n","\n","Database_Administrator     0.9284    0.8963    0.9121       434\n","   Front_End_Developer     0.8603    0.9149    0.8868       505\n","        Java_Developer     0.8519    0.8593    0.8556       455\n"," Network_Administrator     0.8436    0.8163    0.8297       588\n","       Project_manager     0.8752    0.8953    0.8851       611\n","      Python_Developer     0.9378    0.9306    0.9342       389\n","      Security_Analyst     0.8808    0.8765    0.8786       413\n","    Software_Developer     0.9542    0.9580    0.9561      2002\n"," Systems_Administrator     0.8216    0.8689    0.8446       816\n","         Web_Developer     0.7940    0.8669    0.8288       849\n","\n","             micro avg     0.8820    0.9000    0.8909      7062\n","             macro avg     0.8748    0.8883    0.8812      7062\n","          weighted avg     0.8835    0.9000    0.8914      7062\n","           samples avg     0.8846    0.9004    0.8764      7062\n","\n","----------------------------------------------------------------------\n","[2022-08-29 04:13:31.730995] Epoch: 32, Step: 50/750, Avg. Running Loss: 0.012\n","[2022-08-29 04:14:52.239448] Epoch: 32, Step: 100/750, Avg. Running Loss: 0.004\n","[2022-08-29 04:16:12.802436] Epoch: 32, Step: 150/750, Avg. Running Loss: 0.006\n","[2022-08-29 04:17:33.727760] Epoch: 32, Step: 200/750, Avg. Running Loss: 0.005\n","[2022-08-29 04:18:54.493502] Epoch: 32, Step: 250/750, Avg. Running Loss: 0.007\n","[2022-08-29 04:20:15.102863] Epoch: 32, Step: 300/750, Avg. Running Loss: 0.005\n","[2022-08-29 04:21:35.353286] Epoch: 32, Step: 350/750, Avg. Running Loss: 0.004\n","[2022-08-29 04:22:55.947709] Epoch: 32, Step: 400/750, Avg. Running Loss: 0.004\n","[2022-08-29 04:24:16.417572] Epoch: 32, Step: 450/750, Avg. Running Loss: 0.005\n","[2022-08-29 04:25:36.959479] Epoch: 32, Step: 500/750, Avg. Running Loss: 0.004\n","[2022-08-29 04:26:57.494259] Epoch: 32, Step: 550/750, Avg. Running Loss: 0.012\n","[2022-08-29 04:28:17.639344] Epoch: 32, Step: 600/750, Avg. Running Loss: 0.005\n","[2022-08-29 04:29:37.877858] Epoch: 32, Step: 650/750, Avg. Running Loss: 0.003\n","[2022-08-29 04:30:58.486594] Epoch: 32, Step: 700/750, Avg. Running Loss: 0.003\n","[2022-08-29 04:32:19.157241] Epoch: 32, Step: 750/750, Avg. Running Loss: 0.006\n","----------------------------------------------------------------------\n","[2022-08-29 04:34:48.746569] Epoch: 32, Accuracy (Exact Match Ratio) Score=0.72375\n","[2022-08-29 04:34:48.746606] Epoch: 32, Hamming Loss=0.03545\n","[2022-08-29 04:34:48.746620] Epoch: 32, Classification Report:\n","                        precision    recall  f1-score   support\n","\n","Database_Administrator     0.9057    0.9078    0.9068       434\n","   Front_End_Developer     0.8657    0.9188    0.8915       505\n","        Java_Developer     0.9131    0.8549    0.8831       455\n"," Network_Administrator     0.8424    0.8180    0.8300       588\n","       Project_manager     0.8710    0.8838    0.8773       611\n","      Python_Developer     0.9332    0.9332    0.9332       389\n","      Security_Analyst     0.8908    0.8692    0.8799       413\n","    Software_Developer     0.9644    0.9595    0.9619      2002\n"," Systems_Administrator     0.9040    0.8542    0.8784       816\n","         Web_Developer     0.8278    0.8492    0.8384       849\n","\n","             micro avg     0.9023    0.8962    0.8993      7062\n","             macro avg     0.8918    0.8849    0.8880      7062\n","          weighted avg     0.9028    0.8962    0.8992      7062\n","           samples avg     0.8988    0.8972    0.8828      7062\n","\n","----------------------------------------------------------------------\n","[2022-08-29 04:36:08.505271] Epoch: 33, Step: 50/750, Avg. Running Loss: 0.005\n","[2022-08-29 04:37:29.074506] Epoch: 33, Step: 100/750, Avg. Running Loss: 0.002\n","[2022-08-29 04:38:49.450365] Epoch: 33, Step: 150/750, Avg. Running Loss: 0.004\n","[2022-08-29 04:40:10.020341] Epoch: 33, Step: 200/750, Avg. Running Loss: 0.005\n","[2022-08-29 04:41:30.464213] Epoch: 33, Step: 250/750, Avg. Running Loss: 0.005\n","[2022-08-29 04:42:50.966376] Epoch: 33, Step: 300/750, Avg. Running Loss: 0.003\n","[2022-08-29 04:44:11.483469] Epoch: 33, Step: 350/750, Avg. Running Loss: 0.007\n","[2022-08-29 04:45:32.054680] Epoch: 33, Step: 400/750, Avg. Running Loss: 0.004\n","[2022-08-29 04:46:52.471652] Epoch: 33, Step: 450/750, Avg. Running Loss: 0.004\n","[2022-08-29 04:48:12.790156] Epoch: 33, Step: 500/750, Avg. Running Loss: 0.005\n","[2022-08-29 04:49:33.198121] Epoch: 33, Step: 550/750, Avg. Running Loss: 0.005\n","[2022-08-29 04:50:53.517435] Epoch: 33, Step: 600/750, Avg. Running Loss: 0.005\n","[2022-08-29 04:52:14.042399] Epoch: 33, Step: 650/750, Avg. Running Loss: 0.003\n","[2022-08-29 04:53:34.636722] Epoch: 33, Step: 700/750, Avg. Running Loss: 0.004\n","[2022-08-29 04:54:55.293168] Epoch: 33, Step: 750/750, Avg. Running Loss: 0.005\n","----------------------------------------------------------------------\n","[2022-08-29 04:57:25.174980] Epoch: 33, Accuracy (Exact Match Ratio) Score=0.72225\n","[2022-08-29 04:57:25.175036] Epoch: 33, Hamming Loss=0.036025\n","[2022-08-29 04:57:25.175069] Epoch: 33, Classification Report:\n","                        precision    recall  f1-score   support\n","\n","Database_Administrator     0.9245    0.9032    0.9138       434\n","   Front_End_Developer     0.8684    0.9149    0.8910       505\n","        Java_Developer     0.9097    0.8418    0.8744       455\n"," Network_Administrator     0.8141    0.8265    0.8203       588\n","       Project_manager     0.8565    0.8985    0.8770       611\n","      Python_Developer     0.9190    0.9332    0.9260       389\n","      Security_Analyst     0.8768    0.8789    0.8779       413\n","    Software_Developer     0.9639    0.9590    0.9614      2002\n"," Systems_Administrator     0.9067    0.8456    0.8751       816\n","         Web_Developer     0.8376    0.8504    0.8440       849\n","\n","             micro avg     0.8993    0.8963    0.8978      7062\n","             macro avg     0.8877    0.8852    0.8861      7062\n","          weighted avg     0.9000    0.8963    0.8979      7062\n","           samples avg     0.8962    0.8970    0.8813      7062\n","\n","----------------------------------------------------------------------\n","[2022-08-29 04:58:44.653189] Epoch: 34, Step: 50/750, Avg. Running Loss: 0.004\n","[2022-08-29 05:00:04.965494] Epoch: 34, Step: 100/750, Avg. Running Loss: 0.003\n","[2022-08-29 05:01:25.540396] Epoch: 34, Step: 150/750, Avg. Running Loss: 0.003\n","[2022-08-29 05:02:46.210871] Epoch: 34, Step: 200/750, Avg. Running Loss: 0.004\n","[2022-08-29 05:04:06.654397] Epoch: 34, Step: 250/750, Avg. Running Loss: 0.005\n","[2022-08-29 05:05:27.036151] Epoch: 34, Step: 300/750, Avg. Running Loss: 0.002\n","[2022-08-29 05:06:47.127740] Epoch: 34, Step: 350/750, Avg. Running Loss: 0.005\n","[2022-08-29 05:08:07.401776] Epoch: 34, Step: 400/750, Avg. Running Loss: 0.004\n","[2022-08-29 05:09:27.636020] Epoch: 34, Step: 450/750, Avg. Running Loss: 0.003\n","[2022-08-29 05:10:47.982226] Epoch: 34, Step: 500/750, Avg. Running Loss: 0.004\n","[2022-08-29 05:12:08.519623] Epoch: 34, Step: 550/750, Avg. Running Loss: 0.003\n","[2022-08-29 05:13:29.051222] Epoch: 34, Step: 600/750, Avg. Running Loss: 0.006\n","[2022-08-29 05:14:49.246717] Epoch: 34, Step: 650/750, Avg. Running Loss: 0.004\n","[2022-08-29 05:16:09.799349] Epoch: 34, Step: 700/750, Avg. Running Loss: 0.005\n","[2022-08-29 05:17:30.228898] Epoch: 34, Step: 750/750, Avg. Running Loss: 0.007\n","----------------------------------------------------------------------\n","[2022-08-29 05:19:59.903698] Epoch: 34, Accuracy (Exact Match Ratio) Score=0.73175\n","[2022-08-29 05:19:59.903751] Epoch: 34, Hamming Loss=0.034575\n","[2022-08-29 05:19:59.903801] Epoch: 34, Classification Report:\n","                        precision    recall  f1-score   support\n","\n","Database_Administrator     0.8968    0.9009    0.8989       434\n","   Front_End_Developer     0.8902    0.9149    0.9023       505\n","        Java_Developer     0.8803    0.8725    0.8764       455\n"," Network_Administrator     0.8536    0.8129    0.8328       588\n","       Project_manager     0.8824    0.8969    0.8896       611\n","      Python_Developer     0.9476    0.9306    0.9390       389\n","      Security_Analyst     0.8615    0.8886    0.8749       413\n","    Software_Developer     0.9551    0.9660    0.9605      2002\n"," Systems_Administrator     0.8983    0.8554    0.8763       816\n","         Web_Developer     0.8899    0.8092    0.8476       849\n","\n","             micro avg     0.9074    0.8955    0.9014      7062\n","             macro avg     0.8956    0.8848    0.8898      7062\n","          weighted avg     0.9070    0.8955    0.9009      7062\n","           samples avg     0.9030    0.8975    0.8856      7062\n","\n","----------------------------------------------------------------------\n","[2022-08-29 05:21:19.646149] Epoch: 35, Step: 50/750, Avg. Running Loss: 0.003\n","[2022-08-29 05:22:39.983987] Epoch: 35, Step: 100/750, Avg. Running Loss: 0.003\n","[2022-08-29 05:24:00.340451] Epoch: 35, Step: 150/750, Avg. Running Loss: 0.007\n","[2022-08-29 05:25:20.445211] Epoch: 35, Step: 200/750, Avg. Running Loss: 0.005\n","[2022-08-29 05:26:40.767949] Epoch: 35, Step: 250/750, Avg. Running Loss: 0.003\n","[2022-08-29 05:28:01.283973] Epoch: 35, Step: 300/750, Avg. Running Loss: 0.004\n","[2022-08-29 05:29:21.163752] Epoch: 35, Step: 350/750, Avg. Running Loss: 0.004\n","[2022-08-29 05:30:41.754700] Epoch: 35, Step: 400/750, Avg. Running Loss: 0.003\n","[2022-08-29 05:32:02.259424] Epoch: 35, Step: 450/750, Avg. Running Loss: 0.003\n","[2022-08-29 05:33:22.526130] Epoch: 35, Step: 500/750, Avg. Running Loss: 0.003\n","[2022-08-29 05:34:43.060168] Epoch: 35, Step: 550/750, Avg. Running Loss: 0.003\n","[2022-08-29 05:36:03.205661] Epoch: 35, Step: 600/750, Avg. Running Loss: 0.004\n","[2022-08-29 05:37:23.366193] Epoch: 35, Step: 650/750, Avg. Running Loss: 0.003\n","[2022-08-29 05:38:44.115469] Epoch: 35, Step: 700/750, Avg. Running Loss: 0.006\n","[2022-08-29 05:40:04.276063] Epoch: 35, Step: 750/750, Avg. Running Loss: 0.003\n","----------------------------------------------------------------------\n","[2022-08-29 05:42:33.036079] Epoch: 35, Accuracy (Exact Match Ratio) Score=0.74025\n","[2022-08-29 05:42:33.036140] Epoch: 35, Hamming Loss=0.0333\n","[2022-08-29 05:42:33.036174] Epoch: 35, Classification Report:\n","                        precision    recall  f1-score   support\n","\n","Database_Administrator     0.9260    0.8940    0.9097       434\n","   Front_End_Developer     0.9000    0.9089    0.9044       505\n","        Java_Developer     0.8715    0.8791    0.8753       455\n"," Network_Administrator     0.8806    0.8027    0.8399       588\n","       Project_manager     0.9139    0.8854    0.8994       611\n","      Python_Developer     0.9525    0.9280    0.9401       389\n","      Security_Analyst     0.9002    0.8741    0.8870       413\n","    Software_Developer     0.9691    0.9560    0.9625      2002\n"," Systems_Administrator     0.9163    0.8456    0.8795       816\n","         Web_Developer     0.8514    0.8304    0.8408       849\n","\n","             micro avg     0.9181    0.8908    0.9043      7062\n","             macro avg     0.9082    0.8804    0.8939      7062\n","          weighted avg     0.9179    0.8908    0.9040      7062\n","           samples avg     0.9073    0.8924    0.8860      7062\n","\n","----------------------------------------------------------------------\n","[2022-08-29 05:43:52.341300] Epoch: 36, Step: 50/750, Avg. Running Loss: 0.003\n","[2022-08-29 05:45:12.852713] Epoch: 36, Step: 100/750, Avg. Running Loss: 0.003\n","[2022-08-29 05:46:33.405480] Epoch: 36, Step: 150/750, Avg. Running Loss: 0.003\n","[2022-08-29 05:47:53.418426] Epoch: 36, Step: 200/750, Avg. Running Loss: 0.003\n","[2022-08-29 05:49:13.661545] Epoch: 36, Step: 250/750, Avg. Running Loss: 0.004\n","[2022-08-29 05:50:33.818058] Epoch: 36, Step: 300/750, Avg. Running Loss: 0.002\n","[2022-08-29 05:51:53.894725] Epoch: 36, Step: 350/750, Avg. Running Loss: 0.003\n","[2022-08-29 05:53:14.517366] Epoch: 36, Step: 400/750, Avg. Running Loss: 0.004\n","[2022-08-29 05:54:34.648160] Epoch: 36, Step: 450/750, Avg. Running Loss: 0.005\n","[2022-08-29 05:55:54.770092] Epoch: 36, Step: 500/750, Avg. Running Loss: 0.004\n","[2022-08-29 05:57:15.377803] Epoch: 36, Step: 550/750, Avg. Running Loss: 0.003\n","[2022-08-29 05:58:35.986582] Epoch: 36, Step: 600/750, Avg. Running Loss: 0.002\n","[2022-08-29 05:59:56.556547] Epoch: 36, Step: 650/750, Avg. Running Loss: 0.003\n","[2022-08-29 06:01:17.184719] Epoch: 36, Step: 700/750, Avg. Running Loss: 0.002\n","[2022-08-29 06:02:37.563716] Epoch: 36, Step: 750/750, Avg. Running Loss: 0.004\n","----------------------------------------------------------------------\n","[2022-08-29 06:05:07.098260] Epoch: 36, Accuracy (Exact Match Ratio) Score=0.70875\n","[2022-08-29 06:05:07.098305] Epoch: 36, Hamming Loss=0.0379\n","[2022-08-29 06:05:07.098328] Epoch: 36, Classification Report:\n","                        precision    recall  f1-score   support\n","\n","Database_Administrator     0.8267    0.9124    0.8675       434\n","   Front_End_Developer     0.8793    0.9089    0.8939       505\n","        Java_Developer     0.8899    0.8527    0.8709       455\n"," Network_Administrator     0.8139    0.8180    0.8159       588\n","       Project_manager     0.8720    0.9034    0.8875       611\n","      Python_Developer     0.9219    0.9409    0.9313       389\n","      Security_Analyst     0.8657    0.8741    0.8699       413\n","    Software_Developer     0.9662    0.9575    0.9619      2002\n"," Systems_Administrator     0.8823    0.8542    0.8680       816\n","         Web_Developer     0.8220    0.8433    0.8326       849\n","\n","             micro avg     0.8895    0.8968    0.8931      7062\n","             macro avg     0.8740    0.8866    0.8799      7062\n","          weighted avg     0.8903    0.8968    0.8933      7062\n","           samples avg     0.8886    0.8978    0.8776      7062\n","\n","----------------------------------------------------------------------\n","[2022-08-29 06:06:26.512322] Epoch: 37, Step: 50/750, Avg. Running Loss: 0.005\n","[2022-08-29 06:07:47.157433] Epoch: 37, Step: 100/750, Avg. Running Loss: 0.002\n","[2022-08-29 06:09:07.816078] Epoch: 37, Step: 150/750, Avg. Running Loss: 0.004\n","[2022-08-29 06:10:28.261291] Epoch: 37, Step: 200/750, Avg. Running Loss: 0.002\n","[2022-08-29 06:11:48.621911] Epoch: 37, Step: 250/750, Avg. Running Loss: 0.002\n","[2022-08-29 06:13:08.823866] Epoch: 37, Step: 300/750, Avg. Running Loss: 0.002\n","[2022-08-29 06:14:29.151060] Epoch: 37, Step: 350/750, Avg. Running Loss: 0.004\n","[2022-08-29 06:15:49.718470] Epoch: 37, Step: 400/750, Avg. Running Loss: 0.001\n","[2022-08-29 06:17:10.430799] Epoch: 37, Step: 450/750, Avg. Running Loss: 0.004\n","[2022-08-29 06:18:31.037515] Epoch: 37, Step: 500/750, Avg. Running Loss: 0.004\n","[2022-08-29 06:19:51.574369] Epoch: 37, Step: 550/750, Avg. Running Loss: 0.004\n","[2022-08-29 06:21:12.143568] Epoch: 37, Step: 600/750, Avg. Running Loss: 0.003\n","[2022-08-29 06:22:32.480505] Epoch: 37, Step: 650/750, Avg. Running Loss: 0.003\n","[2022-08-29 06:23:52.868368] Epoch: 37, Step: 700/750, Avg. Running Loss: 0.004\n","[2022-08-29 06:25:13.154077] Epoch: 37, Step: 750/750, Avg. Running Loss: 0.002\n","----------------------------------------------------------------------\n","[2022-08-29 06:27:42.452817] Epoch: 37, Accuracy (Exact Match Ratio) Score=0.73625\n","[2022-08-29 06:27:42.452865] Epoch: 37, Hamming Loss=0.03395\n","[2022-08-29 06:27:42.452891] Epoch: 37, Classification Report:\n","                        precision    recall  f1-score   support\n","\n","Database_Administrator     0.9110    0.8963    0.9036       434\n","   Front_End_Developer     0.9105    0.9069    0.9087       505\n","        Java_Developer     0.8975    0.8659    0.8814       455\n"," Network_Administrator     0.8689    0.8112    0.8391       588\n","       Project_manager     0.8954    0.8969    0.8962       611\n","      Python_Developer     0.9381    0.9357    0.9369       389\n","      Security_Analyst     0.9149    0.8596    0.8864       413\n","    Software_Developer     0.9667    0.9570    0.9618      2002\n"," Systems_Administrator     0.9237    0.8456    0.8829       816\n","         Web_Developer     0.8105    0.8563    0.8328       849\n","\n","             micro avg     0.9114    0.8946    0.9030      7062\n","             macro avg     0.9037    0.8832    0.8930      7062\n","          weighted avg     0.9121    0.8946    0.9030      7062\n","           samples avg     0.9037    0.8953    0.8853      7062\n","\n","----------------------------------------------------------------------\n","[2022-08-29 06:29:02.056680] Epoch: 38, Step: 50/750, Avg. Running Loss: 0.003\n","[2022-08-29 06:30:22.493338] Epoch: 38, Step: 100/750, Avg. Running Loss: 0.003\n","[2022-08-29 06:31:42.971222] Epoch: 38, Step: 150/750, Avg. Running Loss: 0.002\n","[2022-08-29 06:33:03.359421] Epoch: 38, Step: 200/750, Avg. Running Loss: 0.003\n","[2022-08-29 06:34:23.700964] Epoch: 38, Step: 250/750, Avg. Running Loss: 0.003\n","[2022-08-29 06:35:44.246866] Epoch: 38, Step: 300/750, Avg. Running Loss: 0.004\n","[2022-08-29 06:37:04.454404] Epoch: 38, Step: 350/750, Avg. Running Loss: 0.003\n","[2022-08-29 06:38:24.828304] Epoch: 38, Step: 400/750, Avg. Running Loss: 0.002\n","[2022-08-29 06:39:45.456230] Epoch: 38, Step: 450/750, Avg. Running Loss: 0.001\n","[2022-08-29 06:41:06.029839] Epoch: 38, Step: 500/750, Avg. Running Loss: 0.003\n","[2022-08-29 06:42:26.730498] Epoch: 38, Step: 550/750, Avg. Running Loss: 0.002\n","[2022-08-29 06:43:47.088347] Epoch: 38, Step: 600/750, Avg. Running Loss: 0.005\n","[2022-08-29 06:45:07.418340] Epoch: 38, Step: 650/750, Avg. Running Loss: 0.002\n","[2022-08-29 06:46:27.749349] Epoch: 38, Step: 700/750, Avg. Running Loss: 0.002\n","[2022-08-29 06:47:48.215788] Epoch: 38, Step: 750/750, Avg. Running Loss: 0.001\n","----------------------------------------------------------------------\n","[2022-08-29 06:50:17.359830] Epoch: 38, Accuracy (Exact Match Ratio) Score=0.7415\n","[2022-08-29 06:50:17.359866] Epoch: 38, Hamming Loss=0.0327\n","[2022-08-29 06:50:17.359881] Epoch: 38, Classification Report:\n","                        precision    recall  f1-score   support\n","\n","Database_Administrator     0.9260    0.8940    0.9097       434\n","   Front_End_Developer     0.9105    0.9069    0.9087       505\n","        Java_Developer     0.9155    0.8571    0.8854       455\n"," Network_Administrator     0.8853    0.8010    0.8411       588\n","       Project_manager     0.8975    0.8887    0.8931       611\n","      Python_Developer     0.9526    0.9306    0.9415       389\n","      Security_Analyst     0.9124    0.8571    0.8839       413\n","    Software_Developer     0.9745    0.9555    0.9649      2002\n"," Systems_Administrator     0.9214    0.8333    0.8752       816\n","         Web_Developer     0.8615    0.8280    0.8444       849\n","\n","             micro avg     0.9250    0.8867    0.9054      7062\n","             macro avg     0.9157    0.8752    0.8948      7062\n","          weighted avg     0.9245    0.8867    0.9050      7062\n","           samples avg     0.9090    0.8888    0.8849      7062\n","\n","Validation Loss Decreased(0.033250--->0.032700) \t Saving The Model\n","----------------------------------------------------------------------\n","[2022-08-29 06:51:38.217389] Epoch: 39, Step: 50/750, Avg. Running Loss: 0.001\n","[2022-08-29 06:52:58.312721] Epoch: 39, Step: 100/750, Avg. Running Loss: 0.001\n","[2022-08-29 06:54:18.891098] Epoch: 39, Step: 150/750, Avg. Running Loss: 0.002\n","[2022-08-29 06:55:39.482860] Epoch: 39, Step: 200/750, Avg. Running Loss: 0.002\n","[2022-08-29 06:57:00.138535] Epoch: 39, Step: 250/750, Avg. Running Loss: 0.001\n","[2022-08-29 06:58:20.774177] Epoch: 39, Step: 300/750, Avg. Running Loss: 0.001\n","[2022-08-29 06:59:41.422911] Epoch: 39, Step: 350/750, Avg. Running Loss: 0.005\n","[2022-08-29 07:01:02.073542] Epoch: 39, Step: 400/750, Avg. Running Loss: 0.003\n","[2022-08-29 07:02:22.555028] Epoch: 39, Step: 450/750, Avg. Running Loss: 0.003\n","[2022-08-29 07:03:43.170233] Epoch: 39, Step: 500/750, Avg. Running Loss: 0.003\n","[2022-08-29 07:05:03.781890] Epoch: 39, Step: 550/750, Avg. Running Loss: 0.002\n","[2022-08-29 07:06:24.303900] Epoch: 39, Step: 600/750, Avg. Running Loss: 0.002\n","[2022-08-29 07:07:44.700158] Epoch: 39, Step: 650/750, Avg. Running Loss: 0.003\n","[2022-08-29 07:09:04.917987] Epoch: 39, Step: 700/750, Avg. Running Loss: 0.002\n","[2022-08-29 07:10:25.348847] Epoch: 39, Step: 750/750, Avg. Running Loss: 0.003\n","----------------------------------------------------------------------\n","[2022-08-29 07:12:54.185994] Epoch: 39, Accuracy (Exact Match Ratio) Score=0.7135\n","[2022-08-29 07:12:54.186039] Epoch: 39, Hamming Loss=0.03725\n","[2022-08-29 07:12:54.187539] Epoch: 39, Classification Report:\n","                        precision    recall  f1-score   support\n","\n","Database_Administrator     0.9076    0.9055    0.9066       434\n","   Front_End_Developer     0.8668    0.9149    0.8902       505\n","        Java_Developer     0.8791    0.8791    0.8791       455\n"," Network_Administrator     0.8139    0.8180    0.8159       588\n","       Project_manager     0.9013    0.8969    0.8991       611\n","      Python_Developer     0.9064    0.9460    0.9258       389\n","      Security_Analyst     0.8643    0.8789    0.8715       413\n","    Software_Developer     0.9525    0.9610    0.9567      2002\n"," Systems_Administrator     0.8903    0.8554    0.8725       816\n","         Web_Developer     0.7978    0.8645    0.8298       849\n","\n","             micro avg     0.8886    0.9022    0.8953      7062\n","             macro avg     0.8780    0.8920    0.8847      7062\n","          weighted avg     0.8894    0.9022    0.8955      7062\n","           samples avg     0.8909    0.9015    0.8807      7062\n","\n","----------------------------------------------------------------------\n","[2022-08-29 07:14:13.801323] Epoch: 40, Step: 50/750, Avg. Running Loss: 0.003\n","[2022-08-29 07:15:34.365076] Epoch: 40, Step: 100/750, Avg. Running Loss: 0.004\n","[2022-08-29 07:16:54.565481] Epoch: 40, Step: 150/750, Avg. Running Loss: 0.005\n","[2022-08-29 07:18:14.914768] Epoch: 40, Step: 200/750, Avg. Running Loss: 0.005\n","[2022-08-29 07:19:35.579758] Epoch: 40, Step: 250/750, Avg. Running Loss: 0.003\n","[2022-08-29 07:20:56.303119] Epoch: 40, Step: 300/750, Avg. Running Loss: 0.003\n","[2022-08-29 07:22:16.694722] Epoch: 40, Step: 350/750, Avg. Running Loss: 0.004\n","[2022-08-29 07:23:36.710341] Epoch: 40, Step: 400/750, Avg. Running Loss: 0.003\n","[2022-08-29 07:24:56.834536] Epoch: 40, Step: 450/750, Avg. Running Loss: 0.002\n","[2022-08-29 07:26:16.968450] Epoch: 40, Step: 500/750, Avg. Running Loss: 0.002\n","[2022-08-29 07:27:36.964762] Epoch: 40, Step: 550/750, Avg. Running Loss: 0.004\n","[2022-08-29 07:28:57.068255] Epoch: 40, Step: 600/750, Avg. Running Loss: 0.003\n","[2022-08-29 07:30:17.404089] Epoch: 40, Step: 650/750, Avg. Running Loss: 0.003\n","[2022-08-29 07:31:37.775650] Epoch: 40, Step: 700/750, Avg. Running Loss: 0.001\n","[2022-08-29 07:32:58.389339] Epoch: 40, Step: 750/750, Avg. Running Loss: 0.011\n","----------------------------------------------------------------------\n","[2022-08-29 07:35:26.461469] Epoch: 40, Accuracy (Exact Match Ratio) Score=0.69175\n","[2022-08-29 07:35:26.462849] Epoch: 40, Hamming Loss=0.0396\n","[2022-08-29 07:35:26.462901] Epoch: 40, Classification Report:\n","                        precision    recall  f1-score   support\n","\n","Database_Administrator     0.9458    0.8848    0.9143       434\n","   Front_End_Developer     0.9232    0.9050    0.9140       505\n","        Java_Developer     0.8507    0.8769    0.8636       455\n"," Network_Administrator     0.8595    0.8112    0.8346       588\n","       Project_manager     0.8967    0.8953    0.8960       611\n","      Python_Developer     0.9455    0.9357    0.9406       389\n","      Security_Analyst     0.8970    0.8644    0.8804       413\n","    Software_Developer     0.9230    0.9640    0.9431      2002\n"," Systems_Administrator     0.9228    0.8493    0.8845       816\n","         Web_Developer     0.7114    0.8363    0.7688       849\n","\n","             micro avg     0.8826    0.8946    0.8886      7062\n","             macro avg     0.8876    0.8823    0.8840      7062\n","          weighted avg     0.8865    0.8946    0.8895      7062\n","           samples avg     0.8861    0.8950    0.8732      7062\n","\n","----------------------------------------------------------------------\n","[2022-08-29 07:36:46.026617] Epoch: 41, Step: 50/750, Avg. Running Loss: 0.003\n","[2022-08-29 07:38:06.512697] Epoch: 41, Step: 100/750, Avg. Running Loss: 0.006\n","[2022-08-29 07:39:26.965341] Epoch: 41, Step: 150/750, Avg. Running Loss: 0.001\n","[2022-08-29 07:40:47.533047] Epoch: 41, Step: 200/750, Avg. Running Loss: 0.005\n","[2022-08-29 07:42:08.146056] Epoch: 41, Step: 250/750, Avg. Running Loss: 0.003\n","[2022-08-29 07:43:28.454230] Epoch: 41, Step: 300/750, Avg. Running Loss: 0.003\n","[2022-08-29 07:44:49.043654] Epoch: 41, Step: 350/750, Avg. Running Loss: 0.004\n","[2022-08-29 07:46:09.313058] Epoch: 41, Step: 400/750, Avg. Running Loss: 0.003\n","[2022-08-29 07:47:29.749495] Epoch: 41, Step: 450/750, Avg. Running Loss: 0.002\n","[2022-08-29 07:48:50.156499] Epoch: 41, Step: 500/750, Avg. Running Loss: 0.001\n","[2022-08-29 07:50:10.572712] Epoch: 41, Step: 550/750, Avg. Running Loss: 0.001\n","[2022-08-29 07:51:31.107070] Epoch: 41, Step: 600/750, Avg. Running Loss: 0.002\n","[2022-08-29 07:52:51.322571] Epoch: 41, Step: 650/750, Avg. Running Loss: 0.001\n","[2022-08-29 07:54:11.828511] Epoch: 41, Step: 700/750, Avg. Running Loss: 0.003\n","[2022-08-29 07:55:32.202590] Epoch: 41, Step: 750/750, Avg. Running Loss: 0.004\n","----------------------------------------------------------------------\n","[2022-08-29 07:58:01.261124] Epoch: 41, Accuracy (Exact Match Ratio) Score=0.74225\n","[2022-08-29 07:58:01.261181] Epoch: 41, Hamming Loss=0.032625\n","[2022-08-29 07:58:01.261216] Epoch: 41, Classification Report:\n","                        precision    recall  f1-score   support\n","\n","Database_Administrator     0.9327    0.8940    0.9129       434\n","   Front_End_Developer     0.9232    0.9050    0.9140       505\n","        Java_Developer     0.8968    0.8593    0.8777       455\n"," Network_Administrator     0.8702    0.8095    0.8388       588\n","       Project_manager     0.8982    0.8953    0.8967       611\n","      Python_Developer     0.9430    0.9357    0.9394       389\n","      Security_Analyst     0.8911    0.8717    0.8813       413\n","    Software_Developer     0.9702    0.9605    0.9654      2002\n"," Systems_Administrator     0.9179    0.8493    0.8822       816\n","         Web_Developer     0.8578    0.8316    0.8445       849\n","\n","             micro avg     0.9200    0.8928    0.9062      7062\n","             macro avg     0.9101    0.8812    0.8953      7062\n","          weighted avg     0.9196    0.8928    0.9059      7062\n","           samples avg     0.9108    0.8947    0.8886      7062\n","\n","Validation Loss Decreased(0.032700--->0.032625) \t Saving The Model\n","----------------------------------------------------------------------\n","[2022-08-29 07:59:21.820458] Epoch: 42, Step: 50/750, Avg. Running Loss: 0.002\n","[2022-08-29 08:00:42.238399] Epoch: 42, Step: 100/750, Avg. Running Loss: 0.001\n","[2022-08-29 08:02:02.668094] Epoch: 42, Step: 150/750, Avg. Running Loss: 0.001\n","[2022-08-29 08:03:23.107991] Epoch: 42, Step: 200/750, Avg. Running Loss: 0.001\n","[2022-08-29 08:04:43.635974] Epoch: 42, Step: 250/750, Avg. Running Loss: 0.002\n","[2022-08-29 08:06:04.272504] Epoch: 42, Step: 300/750, Avg. Running Loss: 0.002\n","[2022-08-29 08:07:24.905771] Epoch: 42, Step: 350/750, Avg. Running Loss: 0.002\n","[2022-08-29 08:08:45.656875] Epoch: 42, Step: 400/750, Avg. Running Loss: 0.001\n","[2022-08-29 08:10:06.125292] Epoch: 42, Step: 450/750, Avg. Running Loss: 0.003\n","[2022-08-29 08:11:26.716052] Epoch: 42, Step: 500/750, Avg. Running Loss: 0.003\n","[2022-08-29 08:12:47.382808] Epoch: 42, Step: 550/750, Avg. Running Loss: 0.002\n","[2022-08-29 08:14:07.928053] Epoch: 42, Step: 600/750, Avg. Running Loss: 0.003\n","[2022-08-29 08:15:28.604809] Epoch: 42, Step: 650/750, Avg. Running Loss: 0.002\n","[2022-08-29 08:16:49.351866] Epoch: 42, Step: 700/750, Avg. Running Loss: 0.001\n","[2022-08-29 08:18:09.939098] Epoch: 42, Step: 750/750, Avg. Running Loss: 0.002\n","----------------------------------------------------------------------\n","[2022-08-29 08:20:39.283901] Epoch: 42, Accuracy (Exact Match Ratio) Score=0.72925\n","[2022-08-29 08:20:39.283946] Epoch: 42, Hamming Loss=0.034925\n","[2022-08-29 08:20:39.283967] Epoch: 42, Classification Report:\n","                        precision    recall  f1-score   support\n","\n","Database_Administrator     0.9034    0.9055    0.9045       434\n","   Front_End_Developer     0.8941    0.9030    0.8985       505\n","        Java_Developer     0.9019    0.8484    0.8743       455\n"," Network_Administrator     0.8166    0.8180    0.8173       588\n","       Project_manager     0.8933    0.8903    0.8918       611\n","      Python_Developer     0.9406    0.9357    0.9381       389\n","      Security_Analyst     0.8870    0.8741    0.8805       413\n","    Software_Developer     0.9705    0.9545    0.9625      2002\n"," Systems_Administrator     0.9010    0.8591    0.8795       816\n","         Web_Developer     0.8442    0.8422    0.8432       849\n","\n","             micro avg     0.9070    0.8938    0.9004      7062\n","             macro avg     0.8953    0.8831    0.8890      7062\n","          weighted avg     0.9073    0.8938    0.9004      7062\n","           samples avg     0.9007    0.8952    0.8831      7062\n","\n","----------------------------------------------------------------------\n","[2022-08-29 08:21:58.940140] Epoch: 43, Step: 50/750, Avg. Running Loss: 0.001\n","[2022-08-29 08:23:19.592006] Epoch: 43, Step: 100/750, Avg. Running Loss: 0.001\n","[2022-08-29 08:24:40.229426] Epoch: 43, Step: 150/750, Avg. Running Loss: 0.001\n","[2022-08-29 08:26:01.065335] Epoch: 43, Step: 200/750, Avg. Running Loss: 0.002\n","[2022-08-29 08:27:21.639154] Epoch: 43, Step: 250/750, Avg. Running Loss: 0.002\n","[2022-08-29 08:28:42.029693] Epoch: 43, Step: 300/750, Avg. Running Loss: 0.001\n","[2022-08-29 08:30:02.575709] Epoch: 43, Step: 350/750, Avg. Running Loss: 0.002\n","[2022-08-29 08:31:23.194622] Epoch: 43, Step: 400/750, Avg. Running Loss: 0.002\n","[2022-08-29 08:32:43.761144] Epoch: 43, Step: 450/750, Avg. Running Loss: 0.003\n","[2022-08-29 08:34:04.299791] Epoch: 43, Step: 500/750, Avg. Running Loss: 0.001\n","[2022-08-29 08:35:25.017433] Epoch: 43, Step: 550/750, Avg. Running Loss: 0.001\n","[2022-08-29 08:36:45.709558] Epoch: 43, Step: 600/750, Avg. Running Loss: 0.002\n","[2022-08-29 08:38:06.294164] Epoch: 43, Step: 650/750, Avg. Running Loss: 0.004\n","[2022-08-29 08:39:26.980814] Epoch: 43, Step: 700/750, Avg. Running Loss: 0.001\n","[2022-08-29 08:40:47.668324] Epoch: 43, Step: 750/750, Avg. Running Loss: 0.002\n","----------------------------------------------------------------------\n","[2022-08-29 08:43:17.305583] Epoch: 43, Accuracy (Exact Match Ratio) Score=0.7325\n","[2022-08-29 08:43:17.305620] Epoch: 43, Hamming Loss=0.034175\n","[2022-08-29 08:43:17.305635] Epoch: 43, Classification Report:\n","                        precision    recall  f1-score   support\n","\n","Database_Administrator     0.9349    0.8940    0.9140       434\n","   Front_End_Developer     0.8865    0.9129    0.8995       505\n","        Java_Developer     0.9145    0.8462    0.8790       455\n"," Network_Administrator     0.8605    0.8078    0.8333       588\n","       Project_manager     0.8833    0.8920    0.8876       611\n","      Python_Developer     0.9427    0.9306    0.9366       389\n","      Security_Analyst     0.8970    0.8644    0.8804       413\n","    Software_Developer     0.9731    0.9565    0.9647      2002\n"," Systems_Administrator     0.9257    0.8248    0.8723       816\n","         Web_Developer     0.8378    0.8398    0.8388       849\n","\n","             micro avg     0.9155    0.8884    0.9018      7062\n","             macro avg     0.9056    0.8769    0.8906      7062\n","          weighted avg     0.9158    0.8884    0.9015      7062\n","           samples avg     0.9055    0.8898    0.8831      7062\n","\n","----------------------------------------------------------------------\n","[2022-08-29 08:44:36.902468] Epoch: 44, Step: 50/750, Avg. Running Loss: 0.001\n","[2022-08-29 08:45:57.422600] Epoch: 44, Step: 100/750, Avg. Running Loss: 0.002\n","[2022-08-29 08:47:17.696966] Epoch: 44, Step: 150/750, Avg. Running Loss: 0.001\n","[2022-08-29 08:48:38.049534] Epoch: 44, Step: 200/750, Avg. Running Loss: 0.002\n","[2022-08-29 08:49:58.469362] Epoch: 44, Step: 250/750, Avg. Running Loss: 0.002\n","[2022-08-29 08:51:19.027577] Epoch: 44, Step: 300/750, Avg. Running Loss: 0.002\n","[2022-08-29 08:52:39.661432] Epoch: 44, Step: 350/750, Avg. Running Loss: 0.002\n","[2022-08-29 08:54:00.323680] Epoch: 44, Step: 400/750, Avg. Running Loss: 0.002\n","[2022-08-29 08:55:20.831472] Epoch: 44, Step: 450/750, Avg. Running Loss: 0.001\n","[2022-08-29 08:56:41.342069] Epoch: 44, Step: 500/750, Avg. Running Loss: 0.001\n","[2022-08-29 08:58:01.884738] Epoch: 44, Step: 550/750, Avg. Running Loss: 0.003\n","[2022-08-29 08:59:22.313412] Epoch: 44, Step: 600/750, Avg. Running Loss: 0.001\n","[2022-08-29 09:00:42.974445] Epoch: 44, Step: 650/750, Avg. Running Loss: 0.001\n","[2022-08-29 09:02:03.349213] Epoch: 44, Step: 700/750, Avg. Running Loss: 0.001\n","[2022-08-29 09:03:23.662486] Epoch: 44, Step: 750/750, Avg. Running Loss: 0.002\n","----------------------------------------------------------------------\n","[2022-08-29 09:05:52.375741] Epoch: 44, Accuracy (Exact Match Ratio) Score=0.72475\n","[2022-08-29 09:05:52.375778] Epoch: 44, Hamming Loss=0.035275\n","[2022-08-29 09:05:52.375792] Epoch: 44, Classification Report:\n","                        precision    recall  f1-score   support\n","\n","Database_Administrator     0.9356    0.9032    0.9191       434\n","   Front_End_Developer     0.8366    0.9228    0.8776       505\n","        Java_Developer     0.9141    0.8418    0.8764       455\n"," Network_Administrator     0.8608    0.8095    0.8344       588\n","       Project_manager     0.8867    0.8969    0.8918       611\n","      Python_Developer     0.9406    0.9357    0.9381       389\n","      Security_Analyst     0.8805    0.8741    0.8773       413\n","    Software_Developer     0.9588    0.9650    0.9619      2002\n"," Systems_Administrator     0.8999    0.8591    0.8790       816\n","         Web_Developer     0.8179    0.8516    0.8344       849\n","\n","             micro avg     0.9013    0.8986    0.9000      7062\n","             macro avg     0.8931    0.8860    0.8890      7062\n","          weighted avg     0.9020    0.8986    0.8999      7062\n","           samples avg     0.8997    0.8991    0.8844      7062\n","\n","----------------------------------------------------------------------\n","[2022-08-29 09:07:11.778309] Epoch: 45, Step: 50/750, Avg. Running Loss: 0.002\n","[2022-08-29 09:08:32.281068] Epoch: 45, Step: 100/750, Avg. Running Loss: 0.001\n","[2022-08-29 09:09:52.763922] Epoch: 45, Step: 150/750, Avg. Running Loss: 0.002\n","[2022-08-29 09:11:13.030751] Epoch: 45, Step: 200/750, Avg. Running Loss: 0.002\n","[2022-08-29 09:12:33.541010] Epoch: 45, Step: 250/750, Avg. Running Loss: 0.001\n","[2022-08-29 09:13:54.244085] Epoch: 45, Step: 300/750, Avg. Running Loss: 0.001\n","[2022-08-29 09:15:14.939890] Epoch: 45, Step: 350/750, Avg. Running Loss: 0.002\n","[2022-08-29 09:16:35.446875] Epoch: 45, Step: 400/750, Avg. Running Loss: 0.002\n","[2022-08-29 09:17:55.835390] Epoch: 45, Step: 450/750, Avg. Running Loss: 0.002\n","[2022-08-29 09:19:16.295564] Epoch: 45, Step: 500/750, Avg. Running Loss: 0.001\n","[2022-08-29 09:20:36.710206] Epoch: 45, Step: 550/750, Avg. Running Loss: 0.002\n","[2022-08-29 09:21:57.124861] Epoch: 45, Step: 600/750, Avg. Running Loss: 0.001\n","[2022-08-29 09:23:17.453147] Epoch: 45, Step: 650/750, Avg. Running Loss: 0.002\n","[2022-08-29 09:24:37.800009] Epoch: 45, Step: 700/750, Avg. Running Loss: 0.002\n","[2022-08-29 09:25:58.393047] Epoch: 45, Step: 750/750, Avg. Running Loss: 0.002\n","----------------------------------------------------------------------\n","[2022-08-29 09:28:28.034273] Epoch: 45, Accuracy (Exact Match Ratio) Score=0.72225\n","[2022-08-29 09:28:28.034344] Epoch: 45, Hamming Loss=0.03625\n","[2022-08-29 09:28:28.034395] Epoch: 45, Classification Report:\n","                        precision    recall  f1-score   support\n","\n","Database_Administrator     0.8814    0.9078    0.8944       434\n","   Front_End_Developer     0.8934    0.9129    0.9030       505\n","        Java_Developer     0.8817    0.8681    0.8749       455\n"," Network_Administrator     0.8013    0.8231    0.8121       588\n","       Project_manager     0.8746    0.9018    0.8880       611\n","      Python_Developer     0.9501    0.9306    0.9403       389\n","      Security_Analyst     0.8311    0.8814    0.8555       413\n","    Software_Developer     0.9740    0.9540    0.9639      2002\n"," Systems_Administrator     0.8912    0.8529    0.8716       816\n","         Web_Developer     0.8427    0.8457    0.8442       849\n","\n","             micro avg     0.8976    0.8971    0.8973      7062\n","             macro avg     0.8822    0.8878    0.8848      7062\n","          weighted avg     0.8986    0.8971    0.8976      7062\n","           samples avg     0.8953    0.8984    0.8815      7062\n","\n","----------------------------------------------------------------------\n","[2022-08-29 09:29:47.608179] Epoch: 46, Step: 50/750, Avg. Running Loss: 0.001\n","[2022-08-29 09:31:07.705984] Epoch: 46, Step: 100/750, Avg. Running Loss: 0.001\n","[2022-08-29 09:32:28.157760] Epoch: 46, Step: 150/750, Avg. Running Loss: 0.001\n","[2022-08-29 09:33:48.605738] Epoch: 46, Step: 200/750, Avg. Running Loss: 0.002\n","[2022-08-29 09:35:09.373053] Epoch: 46, Step: 250/750, Avg. Running Loss: 0.002\n","[2022-08-29 09:36:30.062861] Epoch: 46, Step: 300/750, Avg. Running Loss: 0.002\n","[2022-08-29 09:37:50.805150] Epoch: 46, Step: 350/750, Avg. Running Loss: 0.001\n","[2022-08-29 09:39:11.080740] Epoch: 46, Step: 400/750, Avg. Running Loss: 0.001\n","[2022-08-29 09:40:31.478737] Epoch: 46, Step: 450/750, Avg. Running Loss: 0.001\n","[2022-08-29 09:41:51.900498] Epoch: 46, Step: 500/750, Avg. Running Loss: 0.001\n","[2022-08-29 09:43:12.376963] Epoch: 46, Step: 550/750, Avg. Running Loss: 0.001\n","[2022-08-29 09:44:32.590264] Epoch: 46, Step: 600/750, Avg. Running Loss: 0.002\n","[2022-08-29 09:45:52.907238] Epoch: 46, Step: 650/750, Avg. Running Loss: 0.003\n","[2022-08-29 09:47:13.200491] Epoch: 46, Step: 700/750, Avg. Running Loss: 0.002\n","[2022-08-29 09:48:33.574662] Epoch: 46, Step: 750/750, Avg. Running Loss: 0.001\n","----------------------------------------------------------------------\n","[2022-08-29 09:51:03.046329] Epoch: 46, Accuracy (Exact Match Ratio) Score=0.736\n","[2022-08-29 09:51:03.046384] Epoch: 46, Hamming Loss=0.033925\n","[2022-08-29 09:51:03.046400] Epoch: 46, Classification Report:\n","                        precision    recall  f1-score   support\n","\n","Database_Administrator     0.9353    0.8986    0.9166       434\n","   Front_End_Developer     0.8829    0.9109    0.8967       505\n","        Java_Developer     0.9005    0.8549    0.8771       455\n"," Network_Administrator     0.9025    0.8027    0.8497       588\n","       Project_manager     0.8602    0.9067    0.8829       611\n","      Python_Developer     0.9525    0.9280    0.9401       389\n","      Security_Analyst     0.8759    0.8717    0.8738       413\n","    Software_Developer     0.9648    0.9590    0.9619      2002\n"," Systems_Administrator     0.9183    0.8542    0.8851       816\n","         Web_Developer     0.8363    0.8422    0.8392       849\n","\n","             micro avg     0.9116    0.8946    0.9030      7062\n","             macro avg     0.9029    0.8829    0.8923      7062\n","          weighted avg     0.9121    0.8946    0.9028      7062\n","           samples avg     0.9057    0.8958    0.8867      7062\n","\n","----------------------------------------------------------------------\n","[2022-08-29 09:52:22.859867] Epoch: 47, Step: 50/750, Avg. Running Loss: 0.002\n","[2022-08-29 09:53:43.637150] Epoch: 47, Step: 100/750, Avg. Running Loss: 0.002\n","[2022-08-29 09:55:03.815666] Epoch: 47, Step: 150/750, Avg. Running Loss: 0.002\n","[2022-08-29 09:56:24.259006] Epoch: 47, Step: 200/750, Avg. Running Loss: 0.002\n","[2022-08-29 09:57:45.001980] Epoch: 47, Step: 250/750, Avg. Running Loss: 0.002\n","[2022-08-29 09:59:05.612790] Epoch: 47, Step: 300/750, Avg. Running Loss: 0.001\n","[2022-08-29 10:00:26.056144] Epoch: 47, Step: 350/750, Avg. Running Loss: 0.002\n","[2022-08-29 10:01:46.578128] Epoch: 47, Step: 400/750, Avg. Running Loss: 0.002\n","[2022-08-29 10:03:07.274033] Epoch: 47, Step: 450/750, Avg. Running Loss: 0.003\n","[2022-08-29 10:04:27.628013] Epoch: 47, Step: 500/750, Avg. Running Loss: 0.003\n","[2022-08-29 10:05:47.894304] Epoch: 47, Step: 550/750, Avg. Running Loss: 0.002\n","[2022-08-29 10:07:08.516770] Epoch: 47, Step: 600/750, Avg. Running Loss: 0.001\n","[2022-08-29 10:08:29.178364] Epoch: 47, Step: 650/750, Avg. Running Loss: 0.001\n","[2022-08-29 10:09:49.426149] Epoch: 47, Step: 700/750, Avg. Running Loss: 0.002\n","[2022-08-29 10:11:09.703679] Epoch: 47, Step: 750/750, Avg. Running Loss: 0.001\n","----------------------------------------------------------------------\n","[2022-08-29 10:13:39.810960] Epoch: 47, Accuracy (Exact Match Ratio) Score=0.73325\n","[2022-08-29 10:13:39.811003] Epoch: 47, Hamming Loss=0.03405\n","[2022-08-29 10:13:39.811025] Epoch: 47, Classification Report:\n","                        precision    recall  f1-score   support\n","\n","Database_Administrator     0.9289    0.9032    0.9159       434\n","   Front_End_Developer     0.8893    0.9069    0.8980       505\n","        Java_Developer     0.9005    0.8549    0.8771       455\n"," Network_Administrator     0.8345    0.8146    0.8244       588\n","       Project_manager     0.9053    0.8920    0.8986       611\n","      Python_Developer     0.9476    0.9306    0.9390       389\n","      Security_Analyst     0.8756    0.8692    0.8724       413\n","    Software_Developer     0.9663    0.9600    0.9632      2002\n"," Systems_Administrator     0.9209    0.8419    0.8796       816\n","         Web_Developer     0.8530    0.8339    0.8434       849\n","\n","             micro avg     0.9129    0.8922    0.9025      7062\n","             macro avg     0.9022    0.8807    0.8912      7062\n","          weighted avg     0.9128    0.8922    0.9022      7062\n","           samples avg     0.9055    0.8937    0.8852      7062\n","\n","----------------------------------------------------------------------\n","[2022-08-29 10:14:59.446148] Epoch: 48, Step: 50/750, Avg. Running Loss: 0.001\n","[2022-08-29 10:16:19.517134] Epoch: 48, Step: 100/750, Avg. Running Loss: 0.001\n","[2022-08-29 10:17:39.799200] Epoch: 48, Step: 150/750, Avg. Running Loss: 0.003\n","[2022-08-29 10:19:00.371023] Epoch: 48, Step: 200/750, Avg. Running Loss: 0.001\n","[2022-08-29 10:20:21.036296] Epoch: 48, Step: 250/750, Avg. Running Loss: 0.001\n","[2022-08-29 10:21:41.677901] Epoch: 48, Step: 300/750, Avg. Running Loss: 0.001\n","[2022-08-29 10:23:01.998184] Epoch: 48, Step: 350/750, Avg. Running Loss: 0.003\n","[2022-08-29 10:24:22.416576] Epoch: 48, Step: 400/750, Avg. Running Loss: 0.002\n","[2022-08-29 10:25:42.894864] Epoch: 48, Step: 450/750, Avg. Running Loss: 0.001\n","[2022-08-29 10:27:03.296710] Epoch: 48, Step: 500/750, Avg. Running Loss: 0.001\n","[2022-08-29 10:28:23.934083] Epoch: 48, Step: 550/750, Avg. Running Loss: 0.002\n","[2022-08-29 10:29:44.386879] Epoch: 48, Step: 600/750, Avg. Running Loss: 0.001\n","[2022-08-29 10:31:05.121885] Epoch: 48, Step: 650/750, Avg. Running Loss: 0.001\n","[2022-08-29 10:32:25.912239] Epoch: 48, Step: 700/750, Avg. Running Loss: 0.001\n","[2022-08-29 10:33:46.233316] Epoch: 48, Step: 750/750, Avg. Running Loss: 0.001\n","----------------------------------------------------------------------\n","[2022-08-29 10:36:15.508980] Epoch: 48, Accuracy (Exact Match Ratio) Score=0.72775\n","[2022-08-29 10:36:15.509031] Epoch: 48, Hamming Loss=0.03475\n","[2022-08-29 10:36:15.509065] Epoch: 48, Classification Report:\n","                        precision    recall  f1-score   support\n","\n","Database_Administrator     0.9370    0.8917    0.9138       434\n","   Front_End_Developer     0.8566    0.9109    0.8829       505\n","        Java_Developer     0.8932    0.8637    0.8782       455\n"," Network_Administrator     0.8636    0.8078    0.8348       588\n","       Project_manager     0.8997    0.8953    0.8975       611\n","      Python_Developer     0.9551    0.9306    0.9427       389\n","      Security_Analyst     0.8903    0.8644    0.8771       413\n","    Software_Developer     0.9616    0.9635    0.9626      2002\n"," Systems_Administrator     0.8935    0.8529    0.8727       816\n","         Web_Developer     0.8359    0.8398    0.8378       849\n","\n","             micro avg     0.9071    0.8948    0.9009      7062\n","             macro avg     0.8987    0.8821    0.8900      7062\n","          weighted avg     0.9071    0.8948    0.9007      7062\n","           samples avg     0.9024    0.8958    0.8842      7062\n","\n","----------------------------------------------------------------------\n","[2022-08-29 10:37:35.149721] Epoch: 49, Step: 50/750, Avg. Running Loss: 0.001\n","[2022-08-29 10:38:55.927271] Epoch: 49, Step: 100/750, Avg. Running Loss: 0.000\n","[2022-08-29 10:40:16.339758] Epoch: 49, Step: 150/750, Avg. Running Loss: 0.001\n","[2022-08-29 10:41:36.408938] Epoch: 49, Step: 200/750, Avg. Running Loss: 0.003\n","[2022-08-29 10:42:56.957763] Epoch: 49, Step: 250/750, Avg. Running Loss: 0.001\n","[2022-08-29 10:44:17.370744] Epoch: 49, Step: 300/750, Avg. Running Loss: 0.001\n","[2022-08-29 10:45:37.532217] Epoch: 49, Step: 350/750, Avg. Running Loss: 0.001\n","[2022-08-29 10:46:58.058662] Epoch: 49, Step: 400/750, Avg. Running Loss: 0.002\n","[2022-08-29 10:48:18.716242] Epoch: 49, Step: 450/750, Avg. Running Loss: 0.002\n","[2022-08-29 10:49:39.286179] Epoch: 49, Step: 500/750, Avg. Running Loss: 0.002\n","[2022-08-29 10:50:59.810586] Epoch: 49, Step: 550/750, Avg. Running Loss: 0.002\n","[2022-08-29 10:52:20.222797] Epoch: 49, Step: 600/750, Avg. Running Loss: 0.002\n","[2022-08-29 10:53:40.890387] Epoch: 49, Step: 650/750, Avg. Running Loss: 0.001\n","[2022-08-29 10:55:01.331082] Epoch: 49, Step: 700/750, Avg. Running Loss: 0.001\n","[2022-08-29 10:56:21.779530] Epoch: 49, Step: 750/750, Avg. Running Loss: 0.001\n","----------------------------------------------------------------------\n","[2022-08-29 10:58:51.928685] Epoch: 49, Accuracy (Exact Match Ratio) Score=0.7415\n","[2022-08-29 10:58:51.928740] Epoch: 49, Hamming Loss=0.032725\n","[2022-08-29 10:58:51.928764] Epoch: 49, Classification Report:\n","                        precision    recall  f1-score   support\n","\n","Database_Administrator     0.9332    0.9009    0.9168       434\n","   Front_End_Developer     0.8949    0.9109    0.9028       505\n","        Java_Developer     0.9163    0.8418    0.8774       455\n"," Network_Administrator     0.8960    0.8061    0.8487       588\n","       Project_manager     0.9053    0.8920    0.8986       611\n","      Python_Developer     0.9526    0.9306    0.9415       389\n","      Security_Analyst     0.9263    0.8523    0.8878       413\n","    Software_Developer     0.9611    0.9620    0.9616      2002\n"," Systems_Administrator     0.9234    0.8419    0.8808       816\n","         Web_Developer     0.8442    0.8422    0.8432       849\n","\n","             micro avg     0.9207    0.8914    0.9058      7062\n","             macro avg     0.9153    0.8781    0.8959      7062\n","          weighted avg     0.9206    0.8914    0.9054      7062\n","           samples avg     0.9101    0.8927    0.8871      7062\n","\n","----------------------------------------------------------------------\n"]}]},{"cell_type":"markdown","source":["# 9 Plotting Training Performance"],"metadata":{"id":"ZUP-2bDYOxXE"}},{"cell_type":"code","source":["plt.figure(figsize=(10,5))\n","plt.title(\"Loss/Accuracy\")\n","plt.plot(train_losses, label=\"train_losses\")\n","plt.plot(eval_accuracies, label=\"eval_accuracies\")\n","plt.plot(eval_hamming_losses, label=\"eval_hamming_losses\")\n","plt.xlabel(\"Epoch\")\n","plt.legend()\n","plt.grid()\n","plt.show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":350},"id":"6grnJMU0R1WR","executionInfo":{"status":"ok","timestamp":1661770733565,"user_tz":420,"elapsed":57,"user":{"displayName":"Rafael Paravia","userId":"14697750106415239588"}},"outputId":"214c5757-845c-4de5-c68d-c3ce7dc63340"},"execution_count":16,"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 720x360 with 1 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"markdown","source":["# 10 Final Testing"],"metadata":{"id":"cxPp8pnqQNG7"}},{"cell_type":"code","source":["def test_final_model():\n","    final_model = torch.load(FINAL_MODEL_PATH)\n","    final_model.eval()\n","    targets=[]\n","    predictions=[]\n","\n","    with torch.no_grad():\n","        for _, data in enumerate(testing_loader, 0):\n","            ids = data['ids'].to(DEVICE, dtype = torch.long)\n","            mask = data['mask'].to(DEVICE, dtype = torch.long)\n","            token_type_ids = data['token_type_ids'].to(DEVICE, dtype = torch.long)\n","            batch_targets = data['targets'].to(DEVICE, dtype = torch.float)\n","            batch_predictions = model(ids, mask, token_type_ids)\n","            targets.extend(batch_targets.cpu().detach().numpy().tolist())\n","            predictions.extend(torch.sigmoid(batch_predictions).cpu().detach().numpy().tolist())\n","    predictions = np.array(predictions) >= 0.5\n","\n","    print('----------------------------------------------------------------------')\n","    print('MultiLabel Confusion Matrix:')\n","    print(multilabel_confusion_matrix(targets, predictions))\n","    print(f'[{datetime.now()}] Accuracy (Exact Match Ratio) Score={accuracy_score(targets, predictions)}')\n","    print(f'[{datetime.now()}] Hamming Loss={hamming_loss(targets, predictions)}')\n","    print(f'[{datetime.now()}] Classification Report:')\n","    print(classification_report(targets, predictions, digits=4, zero_division=0, target_names=mlb.classes_))\n","    print('----------------------------------------------------------------------')\n","\n","print('Testing the final model (the best from training')\n","test_final_model()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kUgVf58FQIXo","executionInfo":{"status":"ok","timestamp":1661770882674,"user_tz":420,"elapsed":149125,"user":{"displayName":"Rafael Paravia","userId":"14697750106415239588"}},"outputId":"d5791607-5086-4590-e42b-ad82da87fbc3"},"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["Testing the final model (the best from training\n","----------------------------------------------------------------------\n","MultiLabel Confusion Matrix:\n","[[[3526   47]\n","  [  60  367]]\n","\n"," [[3372   39]\n","  [  54  535]]\n","\n"," [[3514   49]\n","  [  68  369]]\n","\n"," [[3353   53]\n","  [ 120  474]]\n","\n"," [[3346   52]\n","  [  85  517]]\n","\n"," [[3613   13]\n","  [  27  347]]\n","\n"," [[3561   28]\n","  [  70  341]]\n","\n"," [[1866   97]\n","  [  81 1956]]\n","\n"," [[3109   66]\n","  [ 121  704]]\n","\n"," [[2973  130]\n","  [ 130  767]]]\n","[2022-08-29 11:01:21.221438] Accuracy (Exact Match Ratio) Score=0.7415\n","[2022-08-29 11:01:21.233232] Hamming Loss=0.03475\n","[2022-08-29 11:01:21.244437] Classification Report:\n","                        precision    recall  f1-score   support\n","\n","Database_Administrator     0.8865    0.8595    0.8728       427\n","   Front_End_Developer     0.9321    0.9083    0.9200       589\n","        Java_Developer     0.8828    0.8444    0.8632       437\n"," Network_Administrator     0.8994    0.7980    0.8457       594\n","       Project_manager     0.9086    0.8588    0.8830       602\n","      Python_Developer     0.9639    0.9278    0.9455       374\n","      Security_Analyst     0.9241    0.8297    0.8744       411\n","    Software_Developer     0.9528    0.9602    0.9565      2037\n"," Systems_Administrator     0.9143    0.8533    0.8828       825\n","         Web_Developer     0.8551    0.8551    0.8551       897\n","\n","             micro avg     0.9174    0.8866    0.9017      7193\n","             macro avg     0.9119    0.8695    0.8899      7193\n","          weighted avg     0.9171    0.8866    0.9012      7193\n","           samples avg     0.9047    0.8888    0.8822      7193\n","\n","----------------------------------------------------------------------\n"]}]}],"metadata":{"colab":{"collapsed_sections":[],"name":"Experiment-Roberta.ipynb","provenance":[],"machine_shape":"hm","authorship_tag":"ABX9TyNKAvLpTT6zrvjFovPaXnvZ"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"nbformat":4,"nbformat_minor":0}